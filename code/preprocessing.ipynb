{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce8a8939",
   "metadata": {},
   "source": [
    "# **PART 1 - Build dan Init Metadata**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b2f4d6",
   "metadata": {},
   "source": [
    "## **Imports + Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c6fbbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "import warnings\n",
    "\n",
    "TARGET_SR = 16000\n",
    "TARGET_SEC = 15.0\n",
    "MIN_SEC = 1.0\n",
    "MIN_SPEECH_SEC = 2.0\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725f9dab",
   "metadata": {},
   "source": [
    "## **Path split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d7b7b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train audio_dir exists? True -> e:\\tugas-akhir-qiqi\\Dataset\\Train\\train\\audio\n",
      "Val audio_dir exists? True -> e:\\tugas-akhir-qiqi\\Dataset\\Val\\val\\audio\n",
      "Test audio_dir exists? True -> e:\\tugas-akhir-qiqi\\Dataset\\Test\\test\\audio\n"
     ]
    }
   ],
   "source": [
    "ROOT = Path.cwd().parent\n",
    "DATASET = ROOT / \"Dataset\"\n",
    "\n",
    "SPLITS = {\n",
    "    \"Train\": {\n",
    "        \"split_root\": DATASET / \"Train\",\n",
    "        \"audio_dir\":  DATASET / \"Train\" / \"train\" / \"audio\",\n",
    "    },\n",
    "    \"Val\": {\n",
    "        \"split_root\": DATASET / \"Val\",\n",
    "        \"audio_dir\":  DATASET / \"Val\" / \"val\" / \"audio\",\n",
    "    },\n",
    "    \"Test\": {\n",
    "        \"split_root\": DATASET / \"Test\",\n",
    "        \"audio_dir\":  DATASET / \"Test\" / \"test\" / \"audio\",\n",
    "    },\n",
    "}\n",
    "\n",
    "for k,v in SPLITS.items():\n",
    "    print(k, \"audio_dir exists?\", v[\"audio_dir\"].exists(), \"->\", v[\"audio_dir\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eb7991",
   "metadata": {},
   "source": [
    "## **Cek metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c843979d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnG_dev_df shape: (8000, 4)\n",
      "EnG_test_df shape: (2000, 4)\n",
      "Age_dev_df shape: (8000, 3)\n",
      "Age_test_df shape: (2000, 3)\n",
      "\n",
      "\n",
      "EnG_dev_df head:\n",
      "\n",
      "              VideoName    YouTubeID  Ethnicity  Gender\n",
      "0  --Ymqszjv54.001.mp4  --Ymqszjv54          2       1\n",
      "1  --Ymqszjv54.003.mp4  --Ymqszjv54          2       1\n",
      "2  --Ymqszjv54.004.mp4  --Ymqszjv54          2       1\n",
      "3  --Ymqszjv54.005.mp4  --Ymqszjv54          2       1\n",
      "4  -2qsCrkXdWs.001.mp4  -2qsCrkXdWs          2       1\n",
      "EnG_test_df head:\n",
      "\n",
      "              VideoName    YouTubeID  Ethnicity  Gender\n",
      "0  --Ymqszjv54.000.mp4  --Ymqszjv54          2       1\n",
      "1  -10-QQDO_ME.001.mp4  -10-QQDO_ME          2       2\n",
      "2  -10-QQDO_ME.002.mp4  -10-QQDO_ME          2       2\n",
      "3  -10-QQDO_ME.005.mp4  -10-QQDO_ME          2       2\n",
      "4  -4J4xkfN5cI.000.mp4  -4J4xkfN5cI          2       2\n",
      "Age_dev_df head:\n",
      "\n",
      "              VideoName    YouTubeID  AgeGroup\n",
      "0  --Ymqszjv54.001.mp4  --Ymqszjv54         5\n",
      "1  --Ymqszjv54.003.mp4  --Ymqszjv54         5\n",
      "2  --Ymqszjv54.004.mp4  --Ymqszjv54         5\n",
      "3  --Ymqszjv54.005.mp4  --Ymqszjv54         5\n",
      "4  -2qsCrkXdWs.001.mp4  -2qsCrkXdWs         2\n",
      "Age_test_df head:\n",
      "\n",
      "              VideoName    YouTubeID  AgeGroup\n",
      "0  --Ymqszjv54.000.mp4  --Ymqszjv54         6\n",
      "1  -10-QQDO_ME.001.mp4  -10-QQDO_ME         5\n",
      "2  -10-QQDO_ME.002.mp4  -10-QQDO_ME         5\n",
      "3  -10-QQDO_ME.005.mp4  -10-QQDO_ME         5\n",
      "4  -4J4xkfN5cI.000.mp4  -4J4xkfN5cI         2\n"
     ]
    }
   ],
   "source": [
    "#metadata etnichity & gender (csv)\n",
    "EnG_dev_csv = DATASET / \"Eth_gender_annotation\" / \"eth_gender_annotations_dev.csv\"\n",
    "EnG_test_csv = DATASET / \"Eth_gender_annotation\" / \"eth_gender_annotations_test.csv\"\n",
    "\n",
    "#Age Anotation (csv)\n",
    "Age_dev_csv = DATASET / \"Age\" / \"age_anno_dev.csv\"\n",
    "Age_test_csv = DATASET / \"Age\" / \"age_anno_test.csv\"\n",
    "\n",
    "## load metadata csv and print\n",
    "EnG_dev_df = pd.read_csv(EnG_dev_csv, sep=';')\n",
    "EnG_test_df = pd.read_csv(EnG_test_csv, sep=';')\n",
    "Age_dev_df = pd.read_csv(Age_dev_csv)\n",
    "Age_test_df = pd.read_csv(Age_test_csv)\n",
    "print(\"EnG_dev_df shape:\", EnG_dev_df.shape)\n",
    "print(\"EnG_test_df shape:\", EnG_test_df.shape)\n",
    "print(\"Age_dev_df shape:\", Age_dev_df.shape)\n",
    "print(\"Age_test_df shape:\", Age_test_df.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(\"EnG_dev_df head:\\n\\n\", EnG_dev_df.head())\n",
    "    print(\"EnG_test_df head:\\n\\n\", EnG_test_df.head())\n",
    "    print(\"Age_dev_df head:\\n\\n\", Age_dev_df.head())\n",
    "    print(\"Age_test_df head:\\n\\n\", Age_test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6899aa3",
   "metadata": {},
   "source": [
    "Karena ada dev dan test yang ada di EnG dan juga di Age csv, maka keputusan yaitu merge jadi 2 metadata, yaitu dev dan test dan digabungin sekalian dengan Big 5 yang ada di anotasi tiap split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb77c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Train =====\n",
      "annotation dir: e:\\tugas-akhir-qiqi\\Dataset\\Train\\annotation\n",
      "PKL found: ['annotation_training.pkl']\n",
      "Using PKL: annotation_training.pkl | size: 793769\n",
      "Loaded type: <class 'dict'>\n",
      "Dict keys sample: ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'interview', 'openness']\n",
      "First value type: <class 'dict'>\n",
      "pd.DataFrame(obj) shape: (6000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>interview</th>\n",
       "      <th>openness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>J4GQm9j0JZ0.003.mp4</th>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>0.601942</td>\n",
       "      <td>0.504673</td>\n",
       "      <td>0.488889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zEyRyTnIw5I.005.mp4</th>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nskJh7v6v1U.004.mp4</th>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>0.373832</td>\n",
       "      <td>0.511111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6wHQsN5g2RM.000.mp4</th>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.505495</td>\n",
       "      <td>0.398058</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.377778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dQOeQYWIgm8.000.mp4</th>\n",
       "      <td>0.607477</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.622222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     extraversion  neuroticism  agreeableness  \\\n",
       "J4GQm9j0JZ0.003.mp4      0.523364     0.552083       0.626374   \n",
       "zEyRyTnIw5I.005.mp4      0.345794     0.375000       0.472527   \n",
       "nskJh7v6v1U.004.mp4      0.252336     0.291667       0.406593   \n",
       "6wHQsN5g2RM.000.mp4      0.457944     0.489583       0.505495   \n",
       "dQOeQYWIgm8.000.mp4      0.607477     0.489583       0.406593   \n",
       "\n",
       "                     conscientiousness  interview  openness  \n",
       "J4GQm9j0JZ0.003.mp4           0.601942   0.504673  0.488889  \n",
       "zEyRyTnIw5I.005.mp4           0.582524   0.457944  0.366667  \n",
       "nskJh7v6v1U.004.mp4           0.485437   0.373832  0.511111  \n",
       "6wHQsN5g2RM.000.mp4           0.398058   0.457944  0.377778  \n",
       "dQOeQYWIgm8.000.mp4           0.621359   0.570093  0.622222  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index sample: ['J4GQm9j0JZ0.003.mp4', 'zEyRyTnIw5I.005.mp4', 'nskJh7v6v1U.004.mp4', '6wHQsN5g2RM.000.mp4', 'dQOeQYWIgm8.000.mp4', 'eHcRre1YsNA.000.mp4', 'vZpneJlniAE.005.mp4', 'oANKg9_grdA.004.mp4', 'VuadgOz6T7s.000.mp4', '7nhJXn9PI0I.001.mp4']\n",
      "Columns sample: ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'interview', 'openness']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def load_pkl(path: Path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        try:\n",
    "            return pickle.load(f)\n",
    "        except UnicodeDecodeError:\n",
    "            f.seek(0)\n",
    "            return pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "def inspect_annotation(split_name: str):\n",
    "    ann_dir = SPLITS[split_name][\"split_root\"] / \"annotation\"\n",
    "    print(f\"\\n===== {split_name} =====\")\n",
    "    print(\"annotation dir:\", ann_dir)\n",
    "\n",
    "    if not ann_dir.exists():\n",
    "        print(\"-> annotation folder tidak ada\")\n",
    "        return\n",
    "\n",
    "    pkls = sorted(list(ann_dir.glob(\"*.pkl\")) + list(ann_dir.glob(\"*.pickle\")))\n",
    "    print(\"PKL found:\", [p.name for p in pkls])\n",
    "\n",
    "    if not pkls:\n",
    "        print(\"-> tidak ada pkl\")\n",
    "        return\n",
    "\n",
    "    # pilih pkl terbesar (biasanya utama)\n",
    "    pkl_path = max(pkls, key=lambda p: p.stat().st_size)\n",
    "    print(\"Using PKL:\", pkl_path.name, \"| size:\", pkl_path.stat().st_size)\n",
    "\n",
    "    obj = load_pkl(pkl_path)\n",
    "    print(\"Loaded type:\", type(obj))\n",
    "\n",
    "    # kalau sudah DataFrame\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        df = obj\n",
    "        print(\"Already DataFrame. shape:\", df.shape)\n",
    "        display(df.head())\n",
    "        return\n",
    "\n",
    "    # kalau dict\n",
    "    if isinstance(obj, dict):\n",
    "        keys = list(obj.keys())\n",
    "        print(\"Dict keys sample:\", keys[:10])\n",
    "        first_key = keys[0] if keys else None\n",
    "        first_val = obj[first_key] if first_key is not None else None\n",
    "        print(\"First value type:\", type(first_val))\n",
    "\n",
    "        # Coba bikin DataFrame (akan benar kalau dict-of-dict atau dict-of-list)\n",
    "        try:\n",
    "            df = pd.DataFrame(obj)\n",
    "            print(\"pd.DataFrame(obj) shape:\", df.shape)\n",
    "            display(df.head())\n",
    "            print(\"Index sample:\", list(df.index)[:10])\n",
    "            print(\"Columns sample:\", list(df.columns)[:10])\n",
    "\n",
    "            # indikasi butuh transpose:\n",
    "            # - kalau index itu trait (extraversion, openness, ...) dan columns itu video, maka harus transpose\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(\"pd.DataFrame(obj) failed:\", e)\n",
    "            return\n",
    "\n",
    "    # kalau list\n",
    "    if isinstance(obj, list):\n",
    "        print(\"List len:\", len(obj))\n",
    "        print(\"First elem type:\", type(obj[0]) if obj else None)\n",
    "        try:\n",
    "            df = pd.DataFrame(obj)\n",
    "            print(\"pd.DataFrame(list) shape:\", df.shape)\n",
    "            display(df.head())\n",
    "        except Exception as e:\n",
    "            print(\"pd.DataFrame(list) failed:\", e)\n",
    "        return\n",
    "\n",
    "    # tipe lain\n",
    "    print(\"Unhandled type; coba print repr pendek:\")\n",
    "    print(repr(obj)[:500])\n",
    "\n",
    "# Jalankan satu-satu\n",
    "inspect_annotation(\"Train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add07cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Val =====\n",
      "annotation dir: e:\\tugas-akhir-qiqi\\Dataset\\Val\\annotation\n",
      "PKL found: ['annotation_validation.pkl']\n",
      "Using PKL: annotation_validation.pkl | size: 261721\n",
      "Loaded type: <class 'dict'>\n",
      "Dict keys sample: ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'interview', 'openness']\n",
      "First value type: <class 'dict'>\n",
      "pd.DataFrame(obj) shape: (2000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>interview</th>\n",
       "      <th>openness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>modNfUPt3F4.002.mp4</th>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h6LOjpCRXtY.005.mp4</th>\n",
       "      <td>0.439252</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.417582</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>0.439252</td>\n",
       "      <td>0.411111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WER4ww680QQ.004.mp4</th>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.398058</td>\n",
       "      <td>0.373832</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4XnKouozXU.002.mp4</th>\n",
       "      <td>0.364486</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.553398</td>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.322222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OEKg-Tvwcbk.002.mp4</th>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.516484</td>\n",
       "      <td>0.417476</td>\n",
       "      <td>0.383178</td>\n",
       "      <td>0.477778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     extraversion  neuroticism  agreeableness  \\\n",
       "modNfUPt3F4.002.mp4      0.644860     0.593750       0.615385   \n",
       "h6LOjpCRXtY.005.mp4      0.439252     0.520833       0.417582   \n",
       "WER4ww680QQ.004.mp4      0.457944     0.312500       0.428571   \n",
       "c4XnKouozXU.002.mp4      0.364486     0.572917       0.527473   \n",
       "OEKg-Tvwcbk.002.mp4      0.345794     0.468750       0.516484   \n",
       "\n",
       "                     conscientiousness  interview  openness  \n",
       "modNfUPt3F4.002.mp4           0.640777   0.616822  0.555556  \n",
       "h6LOjpCRXtY.005.mp4           0.572816   0.439252  0.411111  \n",
       "WER4ww680QQ.004.mp4           0.398058   0.373832  0.555556  \n",
       "c4XnKouozXU.002.mp4           0.553398   0.523364  0.322222  \n",
       "OEKg-Tvwcbk.002.mp4           0.417476   0.383178  0.477778  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index sample: ['modNfUPt3F4.002.mp4', 'h6LOjpCRXtY.005.mp4', 'WER4ww680QQ.004.mp4', 'c4XnKouozXU.002.mp4', 'OEKg-Tvwcbk.002.mp4', 'PtA7yAu9-VE.003.mp4', 'TmpP2fXeVtk.004.mp4', '1uC-2TZqplE.002.mp4', '_01AyUz9J9I.003.mp4', '_RfHkyf68Zs.000.mp4']\n",
      "Columns sample: ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'interview', 'openness']\n"
     ]
    }
   ],
   "source": [
    "inspect_annotation(\"Val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26325c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Test =====\n",
      "annotation dir: e:\\tugas-akhir-qiqi\\Dataset\\Test\\annotation\n",
      "PKL found: ['annotation_test.pkl']\n",
      "Using PKL: annotation_test.pkl | size: 261721\n",
      "Loaded type: <class 'dict'>\n",
      "Dict keys sample: ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'interview', 'openness']\n",
      "First value type: <class 'dict'>\n",
      "pd.DataFrame(obj) shape: (2000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>interview</th>\n",
       "      <th>openness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>htH89DBizno.004.mp4</th>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.822222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_wf-KszNlk.001.mp4</th>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.514563</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.655556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuYYY3XaJ7Q.001.mp4</th>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.560440</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>0.514019</td>\n",
       "      <td>0.522222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0MB91ku0eEw.005.mp4</th>\n",
       "      <td>0.411215</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.660194</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WpEZOSrENL0.003.mp4</th>\n",
       "      <td>0.317757</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.411111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     extraversion  neuroticism  agreeableness  \\\n",
       "htH89DBizno.004.mp4      0.485981     0.645833       0.681319   \n",
       "p_wf-KszNlk.001.mp4      0.616822     0.593750       0.692308   \n",
       "MuYYY3XaJ7Q.001.mp4      0.467290     0.625000       0.560440   \n",
       "0MB91ku0eEw.005.mp4      0.411215     0.458333       0.714286   \n",
       "WpEZOSrENL0.003.mp4      0.317757     0.437500       0.384615   \n",
       "\n",
       "                     conscientiousness  interview  openness  \n",
       "htH89DBizno.004.mp4           0.669903   0.626168  0.822222  \n",
       "p_wf-KszNlk.001.mp4           0.514563   0.570093  0.655556  \n",
       "MuYYY3XaJ7Q.001.mp4           0.524272   0.514019  0.522222  \n",
       "0MB91ku0eEw.005.mp4           0.660194   0.570093  0.400000  \n",
       "WpEZOSrENL0.003.mp4           0.524272   0.448598  0.411111  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index sample: ['htH89DBizno.004.mp4', 'p_wf-KszNlk.001.mp4', 'MuYYY3XaJ7Q.001.mp4', '0MB91ku0eEw.005.mp4', 'WpEZOSrENL0.003.mp4', 'C2Y9Puk3Obk.004.mp4', 'ask-ZFRztf8.003.mp4', 'TSGpD2NBeCQ.005.mp4', '54JawR1x0II.004.mp4', '9n8dNi-ERQ0.001.mp4']\n",
      "Columns sample: ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'interview', 'openness']\n"
     ]
    }
   ],
   "source": [
    "inspect_annotation(\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3ce5ba",
   "metadata": {},
   "source": [
    "## **Cek Leakage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cebb3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Leakage Check (Group-level) ===\n",
      "Group ID definition: group_id = clip_id.split('.')[0]  (≈ YouTubeID)\n",
      "\n",
      "1) Official split sizes (by extracted audio):\n",
      "   - Train clips: 6,000 | unique groups: 2,624\n",
      "   - Val   clips: 2,000 | unique groups: 1,484\n",
      "   - Test  clips: 2,000 | unique groups: 1,455\n",
      "\n",
      "2) Group overlaps (potential identity leakage):\n",
      "   - Train ∩ Val : 1,222 groups (82.35% of Val groups)\n",
      "   - Train ∩ Test: 1,201 groups (82.54% of Test groups)\n",
      "   - Val   ∩ Test: 689 groups (47.35% of Test groups)\n",
      "\n",
      "3) Test leakage from Train/Val combined:\n",
      "   - (Train ∪ Val) ∩ Test: 1,281 groups (88.04% of Test groups)\n",
      "\n",
      "4) Verdict:\n",
      "   - Group overlap detected between (Train ∪ Val) and Test (identity leakage risk).\n",
      "\n",
      "5) Sample overlapping group IDs:\n",
      "   - Train∩Test sample: --Ymqszjv54, -6otZ7M-Mro, -8asrRvfJWA, -DOqN0d8KHw, -Gl98Jn45Fs, -N6QKrbnaDs, -NwfYYf5xLo, -R2SZu3SYgM, -VTqcHNgH7M, -Wqk9eex6bQ\n",
      "   - Val∩Test   sample: -6otZ7M-Mro, -8asrRvfJWA, -DOqN0d8KHw, -N6QKrbnaDs, -PWjgx2czwY, -R2SZu3SYgM, -RqxrwIxMvE, -VTqcHNgH7M, -Wqk9eex6bQ, -agCXYgb7pI\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def group_id_from_clip_id(clip_id: str) -> str:\n",
    "    # contoh: \"--Ymqszjv54.001\" -> \"--Ymqszjv54\"\n",
    "    return str(clip_id).split(\".\")[0]\n",
    "\n",
    "def get_clip_ids_from_audio(audio_dir: Path):\n",
    "    return {p.stem for p in audio_dir.glob(\"*.wav\")}\n",
    "\n",
    "def pct(a, b):\n",
    "    return (a / b * 100) if b else 0.0\n",
    "\n",
    "def report_leakage():\n",
    "    train_ids = get_clip_ids_from_audio(SPLITS[\"Train\"][\"audio_dir\"])\n",
    "    val_ids   = get_clip_ids_from_audio(SPLITS[\"Val\"][\"audio_dir\"])\n",
    "    test_ids  = get_clip_ids_from_audio(SPLITS[\"Test\"][\"audio_dir\"])\n",
    "\n",
    "    G_train = {group_id_from_clip_id(x) for x in train_ids}\n",
    "    G_val   = {group_id_from_clip_id(x) for x in val_ids}\n",
    "    G_test  = {group_id_from_clip_id(x) for x in test_ids}\n",
    "\n",
    "    # overlaps\n",
    "    ov_tv = G_train & G_val\n",
    "    ov_tt = G_train & G_test\n",
    "    ov_vt = G_val & G_test\n",
    "    ov_any_test = (G_train | G_val) & G_test\n",
    "\n",
    "    lines = []\n",
    "    lines.append(\"=== Leakage Check (Group-level) ===\")\n",
    "    lines.append(\"Group ID definition: group_id = clip_id.split('.')[0]  (≈ YouTubeID)\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"1) Official split sizes (by extracted audio):\")\n",
    "    lines.append(f\"   - Train clips: {len(train_ids):,} | unique groups: {len(G_train):,}\")\n",
    "    lines.append(f\"   - Val   clips: {len(val_ids):,} | unique groups: {len(G_val):,}\")\n",
    "    lines.append(f\"   - Test  clips: {len(test_ids):,} | unique groups: {len(G_test):,}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"2) Group overlaps (potential identity leakage):\")\n",
    "    lines.append(f\"   - Train ∩ Val : {len(ov_tv):,} groups ({pct(len(ov_tv), len(G_val)):.2f}% of Val groups)\")\n",
    "    lines.append(f\"   - Train ∩ Test: {len(ov_tt):,} groups ({pct(len(ov_tt), len(G_test)):.2f}% of Test groups)\")\n",
    "    lines.append(f\"   - Val   ∩ Test: {len(ov_vt):,} groups ({pct(len(ov_vt), len(G_test)):.2f}% of Test groups)\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"3) Test leakage from Train/Val combined:\")\n",
    "    lines.append(f\"   - (Train ∪ Val) ∩ Test: {len(ov_any_test):,} groups ({pct(len(ov_any_test), len(G_test)):.2f}% of Test groups)\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # judgement\n",
    "    if len(ov_any_test) == 0:\n",
    "        verdict = \"No group overlap detected between (Train ∪ Val) and Test (clean at group-level).\"\n",
    "    else:\n",
    "        verdict = \"Group overlap detected between (Train ∪ Val) and Test (identity leakage risk).\"\n",
    "    lines.append(\"4) Verdict:\")\n",
    "    lines.append(f\"   - {verdict}\")\n",
    "\n",
    "    # sample overlaps\n",
    "    def sample_list(s, n=10):\n",
    "        return \", \".join(list(sorted(s))[:n]) if s else \"-\"\n",
    "\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"5) Sample overlapping group IDs:\")\n",
    "    lines.append(f\"   - Train∩Test sample: {sample_list(ov_tt)}\")\n",
    "    lines.append(f\"   - Val∩Test   sample: {sample_list(ov_vt)}\")\n",
    "\n",
    "    print(\"\\n\".join(lines))\n",
    "\n",
    "report_leakage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec667e2f",
   "metadata": {},
   "source": [
    "## **Build Metadata**\n",
    "\n",
    "Akan ada 4 metadata output (Dengan gabungan EnG, anotasi official, dan Age)\n",
    "- meta_train_official.csv\n",
    "- meta_val_official.csv\n",
    "- meta_test_official.csv\n",
    "- meta_master.csv (akan digunakan di split strict, yang mana ini gabungan dari train val dan test, dengan tambahan kolom source official (train, test, val)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ca66e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = ROOT / \"output\" / \"preprocessing\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def norm_clip(x: str) -> str:\n",
    "    return Path(str(x)).stem  # \"--Ymqszjv54.001.mp4\" -> \"--Ymqszjv54.001\"\n",
    "\n",
    "def group_id_from_clip_id(clip_id: str) -> str:\n",
    "    return str(clip_id).split(\".\")[0]  # \"--Ymqszjv54.001\" -> \"--Ymqszjv54\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ebb84e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnG_dev: (8000, 4) | EnG_test: (2000, 4)\n",
      "Age_dev: (8000, 3) | Age_test: (2000, 3)\n"
     ]
    }
   ],
   "source": [
    "# EnG Anotation (csv)\n",
    "EnG_dev_csv = DATASET / \"Eth_gender_annotation\" / \"eth_gender_annotations_dev.csv\"\n",
    "EnG_test_csv = DATASET / \"Eth_gender_annotation\" / \"eth_gender_annotations_test.csv\"\n",
    "\n",
    "# Age Anotation (csv)\n",
    "Age_dev_csv = DATASET / \"Age\" / \"age_anno_dev.csv\"\n",
    "Age_test_csv = DATASET / \"Age\" / \"age_anno_test.csv\"\n",
    "\n",
    "EnG_dev_df = pd.read_csv(EnG_dev_csv, sep=';')\n",
    "EnG_test_df = pd.read_csv(EnG_test_csv, sep=';')\n",
    "Age_dev_df = pd.read_csv(Age_dev_csv)\n",
    "Age_test_df = pd.read_csv(Age_test_csv)\n",
    "\n",
    "print(\"EnG_dev:\", EnG_dev_df.shape, \"| EnG_test:\", EnG_test_df.shape)\n",
    "print(\"Age_dev:\", Age_dev_df.shape, \"| Age_test:\", Age_test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a35ffde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_dev: (8000, 7)\n",
      "meta_test: (2000, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VideoName</th>\n",
       "      <th>YouTubeID</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Gender</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--Ymqszjv54.001.mp4</td>\n",
       "      <td>--Ymqszjv54</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>--Ymqszjv54.001</td>\n",
       "      <td>5</td>\n",
       "      <td>--Ymqszjv54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--Ymqszjv54.003.mp4</td>\n",
       "      <td>--Ymqszjv54</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>--Ymqszjv54.003</td>\n",
       "      <td>5</td>\n",
       "      <td>--Ymqszjv54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--Ymqszjv54.004.mp4</td>\n",
       "      <td>--Ymqszjv54</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>--Ymqszjv54.004</td>\n",
       "      <td>5</td>\n",
       "      <td>--Ymqszjv54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--Ymqszjv54.005.mp4</td>\n",
       "      <td>--Ymqszjv54</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>--Ymqszjv54.005</td>\n",
       "      <td>5</td>\n",
       "      <td>--Ymqszjv54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2qsCrkXdWs.001.mp4</td>\n",
       "      <td>-2qsCrkXdWs</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2qsCrkXdWs.001</td>\n",
       "      <td>2</td>\n",
       "      <td>-2qsCrkXdWs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             VideoName    YouTubeID  Ethnicity  Gender          clip_id  \\\n",
       "0  --Ymqszjv54.001.mp4  --Ymqszjv54          2       1  --Ymqszjv54.001   \n",
       "1  --Ymqszjv54.003.mp4  --Ymqszjv54          2       1  --Ymqszjv54.003   \n",
       "2  --Ymqszjv54.004.mp4  --Ymqszjv54          2       1  --Ymqszjv54.004   \n",
       "3  --Ymqszjv54.005.mp4  --Ymqszjv54          2       1  --Ymqszjv54.005   \n",
       "4  -2qsCrkXdWs.001.mp4  -2qsCrkXdWs          2       1  -2qsCrkXdWs.001   \n",
       "\n",
       "   AgeGroup     group_id  \n",
       "0         5  --Ymqszjv54  \n",
       "1         5  --Ymqszjv54  \n",
       "2         5  --Ymqszjv54  \n",
       "3         5  --Ymqszjv54  \n",
       "4         2  -2qsCrkXdWs  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for df in [EnG_dev_df, EnG_test_df, Age_dev_df, Age_test_df]:\n",
    "    df[\"clip_id\"] = df[\"VideoName\"].map(norm_clip)\n",
    "\n",
    "meta_dev = EnG_dev_df.merge(Age_dev_df[[\"clip_id\", \"AgeGroup\"]], on=\"clip_id\", how=\"left\")\n",
    "meta_test = EnG_test_df.merge(Age_test_df[[\"clip_id\", \"AgeGroup\"]], on=\"clip_id\", how=\"left\")\n",
    "\n",
    "# tambah group_id\n",
    "meta_dev[\"group_id\"] = meta_dev[\"clip_id\"].map(group_id_from_clip_id)\n",
    "meta_test[\"group_id\"] = meta_test[\"clip_id\"].map(group_id_from_clip_id)\n",
    "\n",
    "print(\"meta_dev:\", meta_dev.shape)\n",
    "print(\"meta_test:\", meta_test.shape)\n",
    "display(meta_dev.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8228cb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigFive Train: (6000, 8) | src: e:\\tugas-akhir-qiqi\\Dataset\\Train\\annotation\\annotation_training.pkl\n",
      "BigFive Val  : (2000, 8) | src: e:\\tugas-akhir-qiqi\\Dataset\\Val\\annotation\\annotation_validation.pkl\n",
      "BigFive Test : (2000, 8) | src: e:\\tugas-akhir-qiqi\\Dataset\\Test\\annotation\\annotation_test.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_id</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>openness</th>\n",
       "      <th>interview</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J4GQm9j0JZ0.003</td>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>0.601942</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.504673</td>\n",
       "      <td>J4GQm9j0JZ0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zEyRyTnIw5I.005</td>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>zEyRyTnIw5I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nskJh7v6v1U.004</td>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.373832</td>\n",
       "      <td>nskJh7v6v1U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6wHQsN5g2RM.000</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.505495</td>\n",
       "      <td>0.398058</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>6wHQsN5g2RM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dQOeQYWIgm8.000</td>\n",
       "      <td>0.607477</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>dQOeQYWIgm8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           clip_id  extraversion  neuroticism  agreeableness  \\\n",
       "0  J4GQm9j0JZ0.003      0.523364     0.552083       0.626374   \n",
       "1  zEyRyTnIw5I.005      0.345794     0.375000       0.472527   \n",
       "2  nskJh7v6v1U.004      0.252336     0.291667       0.406593   \n",
       "3  6wHQsN5g2RM.000      0.457944     0.489583       0.505495   \n",
       "4  dQOeQYWIgm8.000      0.607477     0.489583       0.406593   \n",
       "\n",
       "   conscientiousness  openness  interview     group_id  \n",
       "0           0.601942  0.488889   0.504673  J4GQm9j0JZ0  \n",
       "1           0.582524  0.366667   0.457944  zEyRyTnIw5I  \n",
       "2           0.485437  0.511111   0.373832  nskJh7v6v1U  \n",
       "3           0.398058  0.377778   0.457944  6wHQsN5g2RM  \n",
       "4           0.621359  0.622222   0.570093  dQOeQYWIgm8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_pkl(path: Path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        try:\n",
    "            return pickle.load(f)\n",
    "        except UnicodeDecodeError:\n",
    "            f.seek(0)\n",
    "            return pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "def load_bigfive_from_split(split_name: str) -> pd.DataFrame:\n",
    "    ann_dir = SPLITS[split_name][\"split_root\"] / \"annotation\"\n",
    "    pkls = sorted(list(ann_dir.glob(\"*.pkl\")) + list(ann_dir.glob(\"*.pickle\")))\n",
    "    if not pkls:\n",
    "        raise FileNotFoundError(f\"Tidak ada PKL di: {ann_dir}\")\n",
    "\n",
    "    pkl_path = max(pkls, key=lambda p: p.stat().st_size)\n",
    "    obj = load_pkl(pkl_path)\n",
    "\n",
    "    if not isinstance(obj, dict):\n",
    "        raise ValueError(f\"Format PKL bukan dict: {type(obj)} (file: {pkl_path.name})\")\n",
    "\n",
    "    # dict-of-dict (trait -> {clip: value}) -> DataFrame: rows=clip, cols=trait\n",
    "    df = pd.DataFrame(obj)\n",
    "\n",
    "    # index biasanya nama file clip (kadang ada .mp4)\n",
    "    df = df.reset_index().rename(columns={\"index\": \"clip_id\"})\n",
    "    df[\"clip_id\"] = df[\"clip_id\"].astype(str).map(norm_clip)\n",
    "\n",
    "    # keep 5 trait utama (+ interview kalau ada)\n",
    "    keep = [\"clip_id\", \"extraversion\", \"neuroticism\", \"agreeableness\", \"conscientiousness\", \"openness\"]\n",
    "    if \"interview\" in df.columns:\n",
    "        keep.append(\"interview\")\n",
    "    for c in keep:\n",
    "        if c not in df.columns:\n",
    "            df[c] = np.nan\n",
    "\n",
    "    # numeric\n",
    "    for c in [\"extraversion\",\"neuroticism\",\"agreeableness\",\"conscientiousness\",\"openness\",\"interview\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    df[\"group_id\"] = df[\"clip_id\"].map(group_id_from_clip_id)\n",
    "    df.attrs[\"source\"] = str(pkl_path)\n",
    "    return df[keep + [\"group_id\"]]\n",
    "\n",
    "big_train = load_bigfive_from_split(\"Train\")\n",
    "big_val   = load_bigfive_from_split(\"Val\")\n",
    "big_test  = load_bigfive_from_split(\"Test\")\n",
    "\n",
    "print(\"BigFive Train:\", big_train.shape, \"| src:\", big_train.attrs.get(\"source\"))\n",
    "print(\"BigFive Val  :\", big_val.shape,   \"| src:\", big_val.attrs.get(\"source\"))\n",
    "print(\"BigFive Test :\", big_test.shape,  \"| src:\", big_test.attrs.get(\"source\"))\n",
    "display(big_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44400eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio counts: 6000 2000 2000\n"
     ]
    }
   ],
   "source": [
    "def audio_clip_ids(audio_dir: Path) -> set[str]:\n",
    "    return {p.stem for p in audio_dir.glob(\"*.wav\")}\n",
    "\n",
    "train_ids = audio_clip_ids(SPLITS[\"Train\"][\"audio_dir\"])\n",
    "val_ids   = audio_clip_ids(SPLITS[\"Val\"][\"audio_dir\"])\n",
    "test_ids  = audio_clip_ids(SPLITS[\"Test\"][\"audio_dir\"])\n",
    "\n",
    "print(\"audio counts:\", len(train_ids), len(val_ids), len(test_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbb227c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_train_off: (6000, 13)\n",
      "meta_val_off  : (2000, 13)\n",
      "meta_test_off : (2000, 13)\n",
      "meta_master   : (10000, 13)\n",
      "duplicated clip_id in meta_master: 0\n",
      "\n",
      "Saved to: E:\\tugas-akhir-qiqi\\output\\preprocessing\n"
     ]
    }
   ],
   "source": [
    "def build_official_meta(split_name: str) -> pd.DataFrame:\n",
    "    if split_name == \"Train\":\n",
    "        ids = train_ids\n",
    "        demo = meta_dev\n",
    "        big = big_train\n",
    "        split_off = \"train\"\n",
    "    elif split_name == \"Val\":\n",
    "        ids = val_ids\n",
    "        demo = meta_dev\n",
    "        big = big_val\n",
    "        split_off = \"val\"\n",
    "    else:\n",
    "        ids = test_ids\n",
    "        demo = meta_test\n",
    "        big = big_test\n",
    "        split_off = \"test\"\n",
    "\n",
    "    demo_s = demo[demo[\"clip_id\"].isin(ids)].copy()\n",
    "    big_s  = big[big[\"clip_id\"].isin(ids)].copy()\n",
    "\n",
    "    # merge demo + bigfive\n",
    "    out = demo_s.merge(big_s.drop(columns=[\"group_id\"]), on=\"clip_id\", how=\"left\", suffixes=(\"\", \"_bf\"))\n",
    "    out[\"split_official\"] = split_off\n",
    "    out[\"group_id\"] = out[\"clip_id\"].map(group_id_from_clip_id)\n",
    "\n",
    "    # rapihin kolom (optional)\n",
    "    prefer_cols = [\n",
    "        \"group_id\",\"clip_id\",\"split_official\",\n",
    "        \"VideoName\",\"Ethnicity\",\"Gender\",\"AgeGroup\",\n",
    "        \"extraversion\",\"neuroticism\",\"agreeableness\",\"conscientiousness\",\"openness\"\n",
    "    ]\n",
    "    if \"interview\" in out.columns:\n",
    "        prefer_cols.append(\"interview\")\n",
    "\n",
    "    cols = [c for c in prefer_cols if c in out.columns] + [c for c in out.columns if c not in prefer_cols]\n",
    "    out = out[cols]\n",
    "    out = out.drop(columns=[\"YouTubeID\"], errors=\"ignore\")\n",
    "    return out\n",
    "\n",
    "meta_train_off = build_official_meta(\"Train\")\n",
    "meta_val_off   = build_official_meta(\"Val\")\n",
    "meta_test_off  = build_official_meta(\"Test\")\n",
    "\n",
    "# meta_master = gabungan train+val+test (10k) untuk strict split\n",
    "meta_master = pd.concat([meta_train_off, meta_val_off, meta_test_off], ignore_index=True)\n",
    "\n",
    "# sanity checks\n",
    "print(\"meta_train_off:\", meta_train_off.shape)\n",
    "print(\"meta_val_off  :\", meta_val_off.shape)\n",
    "print(\"meta_test_off :\", meta_test_off.shape)\n",
    "print(\"meta_master   :\", meta_master.shape)\n",
    "\n",
    "# pastikan unique clip_id\n",
    "dup = meta_master[\"clip_id\"].duplicated().sum()\n",
    "print(\"duplicated clip_id in meta_master:\", dup)\n",
    "\n",
    "# save\n",
    "(meta_train_off).to_csv(OUT_DIR / \"meta_train_official.csv\", index=False)\n",
    "(meta_val_off).to_csv(OUT_DIR / \"meta_val_official.csv\", index=False)\n",
    "(meta_test_off).to_csv(OUT_DIR / \"meta_test_official.csv\", index=False)\n",
    "(meta_master).to_csv(OUT_DIR / \"meta_master.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved to:\", OUT_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1774249",
   "metadata": {},
   "source": [
    "# **PART 2 - Preprocess Audio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73118579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (10000, 14)\n",
      "split_official\n",
      "train    6000\n",
      "val      2000\n",
      "test     2000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_id</th>\n",
       "      <th>split_official</th>\n",
       "      <th>audio_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--Ymqszjv54.001</td>\n",
       "      <td>train</td>\n",
       "      <td>e:\\tugas-akhir-qiqi\\Dataset\\Train\\train\\audio\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--Ymqszjv54.003</td>\n",
       "      <td>train</td>\n",
       "      <td>e:\\tugas-akhir-qiqi\\Dataset\\Train\\train\\audio\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--Ymqszjv54.004</td>\n",
       "      <td>train</td>\n",
       "      <td>e:\\tugas-akhir-qiqi\\Dataset\\Train\\train\\audio\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--Ymqszjv54.005</td>\n",
       "      <td>train</td>\n",
       "      <td>e:\\tugas-akhir-qiqi\\Dataset\\Train\\train\\audio\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2qsCrkXdWs.001</td>\n",
       "      <td>train</td>\n",
       "      <td>e:\\tugas-akhir-qiqi\\Dataset\\Train\\train\\audio\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           clip_id split_official  \\\n",
       "0  --Ymqszjv54.001          train   \n",
       "1  --Ymqszjv54.003          train   \n",
       "2  --Ymqszjv54.004          train   \n",
       "3  --Ymqszjv54.005          train   \n",
       "4  -2qsCrkXdWs.001          train   \n",
       "\n",
       "                                          audio_path  \n",
       "0  e:\\tugas-akhir-qiqi\\Dataset\\Train\\train\\audio\\...  \n",
       "1  e:\\tugas-akhir-qiqi\\Dataset\\Train\\train\\audio\\...  \n",
       "2  e:\\tugas-akhir-qiqi\\Dataset\\Train\\train\\audio\\...  \n",
       "3  e:\\tugas-akhir-qiqi\\Dataset\\Train\\train\\audio\\...  \n",
       "4  e:\\tugas-akhir-qiqi\\Dataset\\Train\\train\\audio\\...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUT_DIR = ROOT / \"output\" / \"preprocessing\"\n",
    "\n",
    "df = pd.read_csv(OUT_DIR / \"meta_master.csv\")\n",
    "df[\"split_official\"] = df[\"split_official\"].astype(str).str.lower()\n",
    "\n",
    "AUDIO_DIR_MAP = {\n",
    "    \"train\": SPLITS[\"Train\"][\"audio_dir\"],\n",
    "    \"val\":   SPLITS[\"Val\"][\"audio_dir\"],\n",
    "    \"test\":  SPLITS[\"Test\"][\"audio_dir\"],\n",
    "}\n",
    "\n",
    "df[\"audio_path\"] = df.apply(lambda r: AUDIO_DIR_MAP[r[\"split_official\"]] / f\"{r['clip_id']}.wav\", axis=1)\n",
    "\n",
    "print(\"Loaded:\", df.shape)\n",
    "print(df[\"split_official\"].value_counts(dropna=False))\n",
    "df[[\"clip_id\",\"split_official\",\"audio_path\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be11577e",
   "metadata": {},
   "source": [
    "## **CEK SAMPLE RATE, Channel, dan Durasi (hanya 5 sampel)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5fe400f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking audio_path exists: 100%|██████████| 10000/10000 [00:01<00:00, 6988.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio_exists\n",
      "True    10000\n",
      "Name: count, dtype: int64\n",
      "missing (first 10):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_id</th>\n",
       "      <th>split_official</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [clip_id, split_official]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Ymqszjv54.001 | 16000 Hz | 1 ch | 15.3 s\n",
      "--Ymqszjv54.003 | 16000 Hz | 1 ch | 15.3 s\n",
      "--Ymqszjv54.004 | 16000 Hz | 1 ch | 15.3 s\n",
      "--Ymqszjv54.005 | 16000 Hz | 1 ch | 15.3 s\n",
      "-2qsCrkXdWs.001 | 16000 Hz | 1 ch | 15.3 s\n"
     ]
    }
   ],
   "source": [
    "paths = df[\"audio_path\"].tolist()\n",
    "\n",
    "exists = []\n",
    "for p in tqdm(paths, desc=\"Checking audio_path exists\"):\n",
    "    exists.append(Path(p).exists())\n",
    "\n",
    "df[\"audio_exists\"] = exists\n",
    "\n",
    "print(df[\"audio_exists\"].value_counts())\n",
    "\n",
    "miss = df.loc[~df[\"audio_exists\"], [\"clip_id\",\"split_official\"]].head(10)\n",
    "print(\"missing (first 10):\")\n",
    "display(miss)\n",
    "\n",
    "ok = df.loc[df[\"audio_exists\"]].head(5)\n",
    "for _, r in ok.iterrows():\n",
    "    ap = Path(r[\"audio_path\"])\n",
    "    with sf.SoundFile(ap) as f:\n",
    "        dur = len(f) / f.samplerate\n",
    "        print(r[\"clip_id\"], \"|\", f.samplerate, \"Hz |\", f.channels, \"ch |\", round(dur, 2), \"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74a094dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>split_official</th>\n",
       "      <th>VideoName</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>openness</th>\n",
       "      <th>interview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--Ymqszjv54</td>\n",
       "      <td>--Ymqszjv54.001</td>\n",
       "      <td>train</td>\n",
       "      <td>--Ymqszjv54.001.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.551402</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.650485</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.588785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--Ymqszjv54</td>\n",
       "      <td>--Ymqszjv54.003</td>\n",
       "      <td>train</td>\n",
       "      <td>--Ymqszjv54.003.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.392523</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.516484</td>\n",
       "      <td>0.475728</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.392523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--Ymqszjv54</td>\n",
       "      <td>--Ymqszjv54.004</td>\n",
       "      <td>train</td>\n",
       "      <td>--Ymqszjv54.004.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.317757</td>\n",
       "      <td>0.322917</td>\n",
       "      <td>0.549451</td>\n",
       "      <td>0.368932</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.401869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--Ymqszjv54</td>\n",
       "      <td>--Ymqszjv54.005</td>\n",
       "      <td>train</td>\n",
       "      <td>--Ymqszjv54.005.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.373626</td>\n",
       "      <td>0.320388</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.280374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2qsCrkXdWs</td>\n",
       "      <td>-2qsCrkXdWs.001</td>\n",
       "      <td>train</td>\n",
       "      <td>-2qsCrkXdWs.001.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.476636</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.560748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group_id          clip_id split_official            VideoName  \\\n",
       "0  --Ymqszjv54  --Ymqszjv54.001          train  --Ymqszjv54.001.mp4   \n",
       "1  --Ymqszjv54  --Ymqszjv54.003          train  --Ymqszjv54.003.mp4   \n",
       "2  --Ymqszjv54  --Ymqszjv54.004          train  --Ymqszjv54.004.mp4   \n",
       "3  --Ymqszjv54  --Ymqszjv54.005          train  --Ymqszjv54.005.mp4   \n",
       "4  -2qsCrkXdWs  -2qsCrkXdWs.001          train  -2qsCrkXdWs.001.mp4   \n",
       "\n",
       "   Ethnicity  Gender  AgeGroup  extraversion  neuroticism  agreeableness  \\\n",
       "0          2       1         5      0.551402     0.500000       0.527473   \n",
       "1          2       1         5      0.392523     0.427083       0.516484   \n",
       "2          2       1         5      0.317757     0.322917       0.549451   \n",
       "3          2       1         5      0.299065     0.291667       0.373626   \n",
       "4          2       1         2      0.476636     0.604167       0.593407   \n",
       "\n",
       "   conscientiousness  openness  interview  \n",
       "0           0.650485  0.744444   0.588785  \n",
       "1           0.475728  0.466667   0.392523  \n",
       "2           0.368932  0.544444   0.401869  \n",
       "3           0.320388  0.344444   0.280374  \n",
       "4           0.572816  0.611111   0.560748  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=[\"audio_exists\", \"audio_path\"], errors=\"ignore\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a64f1",
   "metadata": {},
   "source": [
    "## **CEK TOTAL DURASI DAN STATISTIK DURASI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "020c6b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning audio metadata: 100%|██████████| 10000/10000 [01:55<00:00, 86.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode OK: 10000 / 10000\n",
      "\n",
      "Sample rate counts:\n",
      "sr\n",
      "16000    10000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Channel counts:\n",
      "channels\n",
      "1    10000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Duration summary (sec):\n",
      "count    10000.000\n",
      "mean        15.271\n",
      "std          0.471\n",
      "min          2.067\n",
      "1%          15.302\n",
      "5%          15.302\n",
      "50%         15.302\n",
      "95%         15.302\n",
      "99%         15.302\n",
      "max         15.302\n",
      "Name: duration_sec, dtype: float64\n",
      "\n",
      "< 1.0s count: 0\n",
      "< 2.0s count: 0\n",
      "< 15.0s count: 73\n",
      "> 15.0s count: 9927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# EDA ringkas: sr, channels, duration (scan semua audio) + summary\n",
    "\n",
    "# mapping split_official -> audio_dir\n",
    "AUDIO_DIR_MAP = {\n",
    "    \"train\": SPLITS[\"Train\"][\"audio_dir\"],\n",
    "    \"val\":   SPLITS[\"Val\"][\"audio_dir\"],\n",
    "    \"test\":  SPLITS[\"Test\"][\"audio_dir\"],\n",
    "}\n",
    "\n",
    "sr_list, ch_list, dur_list, ok_list, err_list = [], [], [], [], []\n",
    "\n",
    "for _, r in tqdm(df.iterrows(), total=len(df), desc=\"Scanning audio metadata\"):\n",
    "    split = str(r[\"split_official\"]).lower()\n",
    "    clip_id = str(r[\"clip_id\"])\n",
    "    ap = AUDIO_DIR_MAP[split] / f\"{clip_id}.wav\"\n",
    "\n",
    "    try:\n",
    "        with sf.SoundFile(ap) as f:\n",
    "            sr = int(f.samplerate)\n",
    "            ch = int(f.channels)\n",
    "            frames = int(len(f))\n",
    "            dur = frames / sr if sr > 0 else 0.0\n",
    "        sr_list.append(sr); ch_list.append(ch); dur_list.append(dur)\n",
    "        ok_list.append(True); err_list.append(\"\")\n",
    "    except Exception as e:\n",
    "        sr_list.append(np.nan); ch_list.append(np.nan); dur_list.append(np.nan)\n",
    "        ok_list.append(False); err_list.append(str(e)[:120])\n",
    "\n",
    "df_eda = df.copy()\n",
    "df_eda[\"decode_ok\"] = ok_list\n",
    "df_eda[\"sr\"] = sr_list\n",
    "df_eda[\"channels\"] = ch_list\n",
    "df_eda[\"duration_sec\"] = dur_list\n",
    "df_eda[\"decode_err\"] = err_list\n",
    "\n",
    "print(\"Decode OK:\", int(df_eda[\"decode_ok\"].sum()), \"/\", len(df_eda))\n",
    "print(\"\\nSample rate counts:\")\n",
    "print(df_eda.loc[df_eda[\"decode_ok\"], \"sr\"].value_counts().head(10))\n",
    "\n",
    "print(\"\\nChannel counts:\")\n",
    "print(df_eda.loc[df_eda[\"decode_ok\"], \"channels\"].value_counts())\n",
    "\n",
    "dur_ok = df_eda.loc[df_eda[\"decode_ok\"], \"duration_sec\"]\n",
    "print(\"\\nDuration summary (sec):\")\n",
    "print(dur_ok.describe(percentiles=[0.01, 0.05, 0.5, 0.95, 0.99]).round(3))\n",
    "\n",
    "print(\"\\n< 1.0s count:\", int((dur_ok < 1.0).sum()))\n",
    "print(\"< 2.0s count:\", int((dur_ok < 2.0).sum()))\n",
    "print(\"< 15.0s count:\", int((dur_ok < 15.0).sum()))\n",
    "print(\"> 15.0s count:\", int((dur_ok > 15.0).sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2d9f33",
   "metadata": {},
   "source": [
    "## **TRIM & PAD 15 Second**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59a64d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trim/Pad to 15s: 100%|██████████| 10000/10000 [02:06<00:00, 78.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: output\\preprocessing\\preprocessed_full\n",
      "Saved: output\\preprocessing\\trim_pad_manifest.csv\n",
      "flag_short counts:\n",
      " flag_short\n",
      "0    9927\n",
      "1      73\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Trim/pad semua audio jadi tepat 15.0 detik (16k mono) + progress bar\n",
    "\n",
    "TARGET_SR = 16000\n",
    "TARGET_SEC = 15.0\n",
    "TARGET_LEN = int(TARGET_SR * TARGET_SEC)\n",
    "\n",
    "OUT_DIR = Path(\"output/preprocessing\")\n",
    "OUT_WAV_DIR = OUT_DIR / \"preprocessed_full\"\n",
    "OUT_WAV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "AUDIO_DIR_MAP = {\n",
    "    \"train\": SPLITS[\"Train\"][\"audio_dir\"],\n",
    "    \"val\":   SPLITS[\"Val\"][\"audio_dir\"],\n",
    "    \"test\":  SPLITS[\"Test\"][\"audio_dir\"],\n",
    "}\n",
    "\n",
    "rows = []\n",
    "\n",
    "for _, r in tqdm(df.iterrows(), total=len(df), desc=\"Trim/Pad to 15s\"):\n",
    "    split = str(r[\"split_official\"]).lower()\n",
    "    clip_id = str(r[\"clip_id\"])\n",
    "    in_path = AUDIO_DIR_MAP[split] / f\"{clip_id}.wav\"\n",
    "    out_path = OUT_WAV_DIR / f\"{clip_id}.wav\"\n",
    "\n",
    "    x, sr = sf.read(in_path, always_2d=False)\n",
    "\n",
    "    # safety checks (harusnya sudah 16k mono, tapi tetap aman)\n",
    "    if isinstance(x, np.ndarray) and x.ndim > 1:\n",
    "        x = x.mean(axis=1)\n",
    "    if sr != TARGET_SR:\n",
    "        raise ValueError(f\"Unexpected sr={sr} for {clip_id}. Expected {TARGET_SR}.\")\n",
    "\n",
    "    orig_len = len(x)\n",
    "    orig_dur = orig_len / sr if sr else 0.0\n",
    "\n",
    "    flag_short = int(orig_len < TARGET_LEN)\n",
    "\n",
    "    if orig_len > TARGET_LEN:\n",
    "        x15 = x[:TARGET_LEN]\n",
    "    elif orig_len < TARGET_LEN:\n",
    "        x15 = np.pad(x, (0, TARGET_LEN - orig_len), mode=\"constant\")\n",
    "    else:\n",
    "        x15 = x\n",
    "\n",
    "    sf.write(out_path, x15, TARGET_SR, subtype=\"PCM_16\")\n",
    "\n",
    "    rows.append({\n",
    "        \"clip_id\": clip_id,\n",
    "        \"split_official\": split,\n",
    "        \"audio_in\": str(in_path),\n",
    "        \"audio_out\": str(out_path),\n",
    "        \"orig_duration_sec\": orig_dur,\n",
    "        \"flag_short\": flag_short\n",
    "    })\n",
    "\n",
    "trim_manifest = pd.DataFrame(rows)\n",
    "trim_manifest.to_csv(OUT_DIR / \"trim_pad_manifest.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\", OUT_WAV_DIR)\n",
    "print(\"Saved:\", OUT_DIR / \"trim_pad_manifest.csv\")\n",
    "print(\"flag_short counts:\\n\", trim_manifest[\"flag_short\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5ec4d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python exe: c:\\Users\\aquq1\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n",
      "Python ver: 3.12.2 (tags/v3.12.2:6abddd9, Feb  6 2024, 21:26:36) [MSC v.1937 64 bit (AMD64)]\n",
      "User site : C:\\Users\\aquq1\\AppData\\Roaming\\Python\\Python312\\site-packages\n",
      "torch exists in env?: True\n"
     ]
    }
   ],
   "source": [
    "import sys, site, pkgutil\n",
    "print(\"Python exe:\", sys.executable)\n",
    "print(\"Python ver:\", sys.version)\n",
    "print(\"User site :\", site.getusersitepackages())\n",
    "print(\"torch exists in env?:\", any(m.name==\"torch\" for m in pkgutil.iter_modules()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65b929",
   "metadata": {},
   "source": [
    "## **SILERO VAD PART 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b431791a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trim_manifest: (10000, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\aquq1/.cache\\torch\\hub\\snakers4_silero-vad_master\n",
      "Silero VAD: 100%|██████████| 10000/10000 [43:53<00:00,  3.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: e:\\tugas-akhir-qiqi\\output\\preprocessing\\vad\\vad_report.csv\n",
      "Saved: e:\\tugas-akhir-qiqi\\output\\preprocessing\\vad\\vad_drop.csv\n",
      "Drop count (speech_sec < 2s): 42\n",
      "\n",
      "Speech_sec summary:\n",
      "count    10000.000\n",
      "mean        13.103\n",
      "std          1.906\n",
      "min          0.000\n",
      "1%           5.721\n",
      "5%           9.663\n",
      "50%         13.612\n",
      "95%         14.934\n",
      "99%         15.000\n",
      "max         15.000\n",
      "Name: speech_sec, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Silero VAD check: hitung speech_sec, voiced_ratio, n_seg untuk semua audio 15s\n",
    "\n",
    "OUT_DIR = ROOT / \"output\" / \"preprocessing\"\n",
    "IN_MANIFEST = OUT_DIR / \"trim_pad_manifest.csv\"\n",
    "VAD_REPORT = OUT_DIR / \"vad\" / \"vad_report.csv\"\n",
    "VAD_DROP = OUT_DIR / \"vad\" / \"vad_drop.csv\"\n",
    "VAD_DROP.parent.mkdir(parents=True, exist_ok=True)\n",
    "VAD_REPORT.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "SR = 16000\n",
    "FIXED_SEC = 15.0\n",
    "MIN_SPEECH_SEC = 2.0  # nanti dipakai buat drop list\n",
    "\n",
    "# load manifest hasil trim/pad\n",
    "trim_manifest = pd.read_csv(IN_MANIFEST)\n",
    "print(\"trim_manifest:\", trim_manifest.shape)\n",
    "\n",
    "# load silero vad\n",
    "try:\n",
    "    import torch\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"torch belum terinstall. Install dulu: pip install torch\") from e\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "model, utils = torch.hub.load(\n",
    "    repo_or_dir=\"snakers4/silero-vad\",\n",
    "    model=\"silero_vad\",\n",
    "    force_reload=False\n",
    ")\n",
    "(get_speech_timestamps, _, _, _, _) = utils\n",
    "model.eval()\n",
    "\n",
    "rows = []\n",
    "for _, r in tqdm(trim_manifest.iterrows(), total=len(trim_manifest), desc=\"Silero VAD\"):\n",
    "    clip_id = str(r[\"clip_id\"])\n",
    "    ap = ROOT / Path(r[\"audio_out\"])  # sudah 16k mono 15s\n",
    "\n",
    "    x, sr = sf.read(ap, always_2d=False)\n",
    "    if sr != SR:\n",
    "        raise ValueError(f\"sr mismatch for {clip_id}: {sr}\")\n",
    "\n",
    "    if isinstance(x, np.ndarray) and x.ndim > 1:\n",
    "        x = x.mean(axis=1)\n",
    "    x = x.astype(np.float32)\n",
    "\n",
    "    wav = torch.from_numpy(x)\n",
    "    ts = get_speech_timestamps(wav, model, sampling_rate=SR)\n",
    "\n",
    "    speech_sec = sum((t[\"end\"] - t[\"start\"]) for t in ts) / SR\n",
    "    n_seg = len(ts)\n",
    "    voiced_ratio = speech_sec / FIXED_SEC\n",
    "\n",
    "    rows.append({\n",
    "        \"clip_id\": clip_id,\n",
    "        \"speech_sec\": float(speech_sec),\n",
    "        \"voiced_ratio\": float(voiced_ratio),\n",
    "        \"n_seg\": int(n_seg),\n",
    "    })\n",
    "\n",
    "vad_df = pd.DataFrame(rows)\n",
    "vad_df.to_csv(VAD_REPORT, index=False)\n",
    "\n",
    "drop_df = vad_df[vad_df[\"speech_sec\"] < MIN_SPEECH_SEC].copy()\n",
    "drop_df[\"reason\"] = \"too_little_speech\"\n",
    "drop_df.to_csv(VAD_DROP, index=False)\n",
    "\n",
    "print(\"Saved:\", VAD_REPORT)\n",
    "print(\"Saved:\", VAD_DROP)\n",
    "print(\"Drop count (speech_sec < 2s):\", len(drop_df))\n",
    "print(\"\\nSpeech_sec summary:\")\n",
    "print(vad_df[\"speech_sec\"].describe(percentiles=[0.01,0.05,0.5,0.95,0.99]).round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a86409",
   "metadata": {},
   "source": [
    "## **CEK ULANG VAD DROP**\n",
    "\n",
    "karena ditemukan beberapa anomali setelah di crosscheck seperti ada audio yang belum ter-ekstrak dengan baik ataupun bug ekstraksi, dan juga ada beberapa audio dengan case khusus seperti suara bisik bisik yang butuh tuning VAD yang lebih baik\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5126580a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop clips: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Re-extract (anti-phase) + fix 15s: 100%|██████████| 42/42 [00:09<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: e:\\tugas-akhir-qiqi\\output\\preprocessing\\trim_pad_manifest_retry.csv\n",
      "Saved: e:\\tugas-akhir-qiqi\\output\\preprocessing\\reextract_failed.csv\n",
      "ok: 42 | failed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import imageio_ffmpeg\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "DATASET = ROOT / \"Dataset\"\n",
    "OUT_DIR = ROOT / \"output\" / \"preprocessing\"\n",
    "\n",
    "VAD_DROP_PATH = OUT_DIR / \"vad\" / \"vad_drop.csv\"\n",
    "drop_df = pd.read_csv(VAD_DROP_PATH)\n",
    "drop_ids = drop_df[\"clip_id\"].astype(str).unique().tolist()\n",
    "print(\"Drop clips:\", len(drop_ids))\n",
    "\n",
    "meta = pd.read_csv(OUT_DIR / \"meta_master.csv\")\n",
    "meta[\"split_official\"] = meta[\"split_official\"].astype(str).str.lower()\n",
    "\n",
    "VIDEO_DIR_MAP = {\n",
    "    \"train\": DATASET / \"Train\" / \"train\",\n",
    "    \"val\":   DATASET / \"Val\" / \"val\",\n",
    "    \"test\":  DATASET / \"Test\" / \"test\",\n",
    "}\n",
    "\n",
    "RAW_REEX_DIR = OUT_DIR / \"reextract_raw\"\n",
    "FIXED15_DIR  = OUT_DIR / \"preprocessed_full_retry\"\n",
    "RAW_REEX_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIXED15_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ffmpeg = imageio_ffmpeg.get_ffmpeg_exe()\n",
    "\n",
    "TARGET_SR = 16000\n",
    "TARGET_SEC = 15.0\n",
    "TARGET_LEN = int(TARGET_SR * TARGET_SEC)\n",
    "\n",
    "PEAK_SILENT_THR = 1e-4\n",
    "RMS_SILENT_THR  = 1e-5\n",
    "\n",
    "STREAM_CANDIDATES = [\"0:a:0\", \"0:a:1\", \"0:a:2\", \"0:a:3\"]\n",
    "\n",
    "def rms(x: np.ndarray) -> float:\n",
    "    x = np.asarray(x)\n",
    "    if x.size == 0:\n",
    "        return 0.0\n",
    "    return float(np.sqrt(np.mean(np.square(x.astype(np.float64)))))\n",
    "\n",
    "def peak(x: np.ndarray) -> float:\n",
    "    x = np.asarray(x)\n",
    "    if x.size == 0:\n",
    "        return 0.0\n",
    "    return float(np.max(np.abs(x)))\n",
    "\n",
    "def best_mono_from_stereo(x: np.ndarray):\n",
    "    \"\"\"\n",
    "    x: (n,2) stereo atau (n,) mono.\n",
    "    Return: mono_signal, chosen_mode (L/R/mean)\n",
    "    \"\"\"\n",
    "    if x.ndim == 1:\n",
    "        return x, \"mono\"\n",
    "\n",
    "    L = x[:, 0]\n",
    "    R = x[:, 1]\n",
    "    M = 0.5 * (L + R)  # mean (bisa cancel kalau beda fase)\n",
    "\n",
    "    # pilih yang RMS paling besar (anti cancellation)\n",
    "    cands = [(\"L\", L), (\"R\", R), (\"mean\", M)]\n",
    "    best_mode, best_sig = max(cands, key=lambda t: rms(t[1]))\n",
    "    return best_sig, best_mode\n",
    "\n",
    "rows = []\n",
    "fails = []\n",
    "\n",
    "for clip_id in tqdm(drop_ids, desc=\"Re-extract (anti-phase) + fix 15s\"):\n",
    "    row = meta.loc[meta[\"clip_id\"].astype(str) == clip_id]\n",
    "    if row.empty:\n",
    "        fails.append({\"clip_id\": clip_id, \"reason\": \"clip_not_in_meta\"})\n",
    "        continue\n",
    "\n",
    "    split = row.iloc[0][\"split_official\"]\n",
    "    video_path = VIDEO_DIR_MAP[split] / f\"{clip_id}.mp4\"\n",
    "    if not video_path.exists():\n",
    "        fails.append({\"clip_id\": clip_id, \"reason\": \"video_missing\", \"video_path\": str(video_path)})\n",
    "        continue\n",
    "\n",
    "    out_wav = FIXED15_DIR / f\"{clip_id}.wav\"\n",
    "\n",
    "    best = None\n",
    "    # best = (score_rms, best_raw_path, stream, chosen_mode, pk, rms)\n",
    "\n",
    "    for stream in STREAM_CANDIDATES:\n",
    "        raw_wav = RAW_REEX_DIR / f\"{clip_id}__{stream.replace(':','_')}.wav\"\n",
    "\n",
    "        # Extract as STEREO (ac=2) to avoid cancellation\n",
    "        cmd = [\n",
    "            ffmpeg, \"-y\",\n",
    "            \"-i\", str(video_path),\n",
    "            \"-map\", stream,\n",
    "            \"-vn\",\n",
    "            \"-ac\", \"2\",\n",
    "            \"-ar\", str(TARGET_SR),\n",
    "            \"-acodec\", \"pcm_s16le\",\n",
    "            str(raw_wav)\n",
    "        ]\n",
    "        r = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "        if r.returncode != 0 or (not raw_wav.exists()):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            x, sr = sf.read(raw_wav, always_2d=True)  # always_2d biar (n, ch)\n",
    "            if sr != TARGET_SR:\n",
    "                continue\n",
    "\n",
    "            mono, mode = best_mono_from_stereo(x)\n",
    "            pk = peak(mono)\n",
    "            rr = rms(mono)\n",
    "\n",
    "            # silent guard\n",
    "            if pk < PEAK_SILENT_THR or rr < RMS_SILENT_THR:\n",
    "                continue\n",
    "\n",
    "            # score pakai RMS (pilih yang paling \"kenceng\" & berisi)\n",
    "            score = rr\n",
    "            if (best is None) or (score > best[0]):\n",
    "                best = (score, raw_wav, stream, mode, pk, rr)\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if best is None:\n",
    "        fails.append({\"clip_id\": clip_id, \"reason\": \"no_valid_audio_stream_or_silent\", \"video_path\": str(video_path)})\n",
    "        continue\n",
    "\n",
    "    _, best_raw, best_stream, best_mode, best_pk, best_rms = best\n",
    "\n",
    "    # Read lagi best_raw dan bikin mono final sesuai mode\n",
    "    x, sr = sf.read(best_raw, always_2d=True)\n",
    "    mono, _ = best_mono_from_stereo(x)\n",
    "\n",
    "    # OPTIONAL: peak normalize ringan biar bisik kebantu (nggak mengubah konten)\n",
    "    pk = peak(mono) + 1e-9\n",
    "    mono = (mono / pk) * 0.98\n",
    "\n",
    "    orig_len = len(mono)\n",
    "    flag_short = int(orig_len < TARGET_LEN)\n",
    "\n",
    "    if orig_len > TARGET_LEN:\n",
    "        x15 = mono[:TARGET_LEN]\n",
    "    elif orig_len < TARGET_LEN:\n",
    "        x15 = np.pad(mono, (0, TARGET_LEN - orig_len), mode=\"constant\")\n",
    "    else:\n",
    "        x15 = mono\n",
    "\n",
    "    sf.write(out_wav, x15.astype(np.float32), TARGET_SR, subtype=\"PCM_16\")\n",
    "\n",
    "    rows.append({\n",
    "        \"clip_id\": clip_id,\n",
    "        \"split_official\": split,\n",
    "        \"video_path\": str(video_path),\n",
    "        \"best_stream\": best_stream,\n",
    "        \"mono_mode\": best_mode,          # L / R / mean / mono\n",
    "        \"raw_wav\": str(best_raw),\n",
    "        \"audio_out\": str(out_wav),\n",
    "        \"orig_duration_sec\": orig_len / TARGET_SR,\n",
    "        \"flag_short\": flag_short,\n",
    "        \"best_rms\": best_rms,\n",
    "        \"best_peak\": best_pk\n",
    "    })\n",
    "\n",
    "retry_manifest = pd.DataFrame(rows)\n",
    "retry_fails = pd.DataFrame(fails)\n",
    "\n",
    "retry_manifest.to_csv(OUT_DIR / \"trim_pad_manifest_retry.csv\", index=False)\n",
    "retry_fails.to_csv(OUT_DIR / \"reextract_failed.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\", OUT_DIR / \"trim_pad_manifest_retry.csv\")\n",
    "print(\"Saved:\", OUT_DIR / \"reextract_failed.csv\")\n",
    "print(\"ok:\", len(retry_manifest), \"| failed:\", len(retry_fails))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd65a29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retry files: (42, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\aquq1/.cache\\torch\\hub\\snakers4_silero-vad_master\n",
      "Silero VAD (tuned): 100%|██████████| 42/42 [00:10<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: e:\\tugas-akhir-qiqi\\output\\preprocessing\\vad\\vad_report_retry.csv\n",
      "Saved: e:\\tugas-akhir-qiqi\\output\\preprocessing\\vad\\vad_drop_retry.csv\n",
      "Still drop (<2s): 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "OUT_DIR = ROOT / Path(\"output/preprocessing\")\n",
    "man = pd.read_csv(OUT_DIR / \"trim_pad_manifest_retry.csv\")\n",
    "print(\"retry files:\", man.shape)\n",
    "\n",
    "VAD_DIR = OUT_DIR / \"vad\"\n",
    "VAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# load silero\n",
    "torch.set_grad_enabled(False)\n",
    "model, utils = torch.hub.load(\"snakers4/silero-vad\", \"silero_vad\", force_reload=False)\n",
    "(get_speech_timestamps, _, _, _, _) = utils\n",
    "model.eval()\n",
    "\n",
    "SR = 16000\n",
    "FIXED_SEC = 15.0\n",
    "MIN_SPEECH_SEC = 2.0\n",
    "\n",
    "# tuning: lebih sensitif untuk bisik-bisik\n",
    "VAD_KW = dict(\n",
    "    threshold=0.35,              # default biasanya 0.5\n",
    "    min_speech_duration_ms=100,  # lebih kecil\n",
    "    min_silence_duration_ms=50,  # lebih kecil\n",
    "    speech_pad_ms=30\n",
    ")\n",
    "\n",
    "rows = []\n",
    "for _, r in tqdm(man.iterrows(), total=len(man), desc=\"Silero VAD (tuned)\"):\n",
    "    clip_id = str(r[\"clip_id\"])\n",
    "    ap = Path(r[\"audio_out\"])\n",
    "\n",
    "    x, sr = sf.read(ap, always_2d=False)\n",
    "    if isinstance(x, np.ndarray) and x.ndim > 1:\n",
    "        x = x.mean(axis=1)\n",
    "    if sr != SR:\n",
    "        raise ValueError(f\"sr mismatch {clip_id}: {sr}\")\n",
    "\n",
    "    x = x.astype(np.float32)\n",
    "\n",
    "    # optional: peak normalize biar bisik lebih kebaca\n",
    "    peak = float(np.max(np.abs(x)) + 1e-9)\n",
    "    x = (x / peak) * 0.98\n",
    "\n",
    "    ts = get_speech_timestamps(torch.from_numpy(x), model, sampling_rate=SR, **VAD_KW)\n",
    "    speech_sec = sum((t[\"end\"] - t[\"start\"]) for t in ts) / SR\n",
    "    n_seg = len(ts)\n",
    "    voiced_ratio = speech_sec / FIXED_SEC\n",
    "\n",
    "    rows.append({\n",
    "        \"clip_id\": clip_id,\n",
    "        \"speech_sec\": float(speech_sec),\n",
    "        \"voiced_ratio\": float(voiced_ratio),\n",
    "        \"n_seg\": int(n_seg),\n",
    "    })\n",
    "\n",
    "vad_retry = pd.DataFrame(rows)\n",
    "vad_retry.to_csv(VAD_DIR / \"vad_report_retry.csv\", index=False)\n",
    "\n",
    "drop_retry = vad_retry[vad_retry[\"speech_sec\"] < MIN_SPEECH_SEC].copy()\n",
    "drop_retry[\"reason\"] = \"too_little_speech\"\n",
    "drop_retry.to_csv(VAD_DIR / \"vad_drop_retry.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\", VAD_DIR / \"vad_report_retry.csv\")\n",
    "print(\"Saved:\", VAD_DIR / \"vad_drop_retry.csv\")\n",
    "print(\"Still drop (<2s):\", len(drop_retry))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fd39fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retry wavs: 42\n",
      "Patched trim_pad_manifest rows: 42\n",
      "Patched vad_report rows: 42\n",
      "Replaced vad_drop.csv with vad_drop_retry.csv\n",
      "Deleted dir: e:\\tugas-akhir-qiqi\\output\\preprocessing\\preprocessed_full_retry\n",
      "Deleted dir: e:\\tugas-akhir-qiqi\\output\\preprocessing\\reextract_raw\n",
      "Deleted file: e:\\tugas-akhir-qiqi\\output\\preprocessing\\trim_pad_manifest_retry.csv\n",
      "Deleted file: e:\\tugas-akhir-qiqi\\output\\preprocessing\\vad\\vad_report_retry.csv\n",
      "Deleted file: e:\\tugas-akhir-qiqi\\output\\preprocessing\\vad\\vad_drop_retry.csv\n",
      "\n",
      "Done. Current key files:\n",
      "- e:\\tugas-akhir-qiqi\\output\\preprocessing\\preprocessed_full\n",
      "- e:\\tugas-akhir-qiqi\\output\\preprocessing\\trim_pad_manifest.csv\n",
      "- e:\\tugas-akhir-qiqi\\output\\preprocessing\\vad\\vad_report.csv\n",
      "- e:\\tugas-akhir-qiqi\\output\\preprocessing\\vad\\vad_drop.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "BASE = ROOT / Path(\"output/preprocessing\")\n",
    "\n",
    "FULL_DIR = BASE / \"preprocessed_full\"\n",
    "RETRY_DIR = BASE / \"preprocessed_full_retry\"\n",
    "RAW_DIR = BASE / \"reextract_raw\"\n",
    "\n",
    "MANIFEST = BASE / \"trim_pad_manifest.csv\"\n",
    "MANIFEST_RETRY = BASE / \"trim_pad_manifest_retry.csv\"\n",
    "\n",
    "VAD_DIR = BASE / \"vad\"\n",
    "VAD_REPORT = VAD_DIR / \"vad_report.csv\"\n",
    "VAD_REPORT_RETRY = VAD_DIR / \"vad_report_retry.csv\"\n",
    "VAD_DROP = VAD_DIR / \"vad_drop.csv\"\n",
    "VAD_DROP_RETRY = VAD_DIR / \"vad_drop_retry.csv\"\n",
    "\n",
    "REEX_FAILED = BASE / \"reextract_failed.csv\"\n",
    "\n",
    "# 1) overwrite audio files\n",
    "if RETRY_DIR.exists():\n",
    "    retry_wavs = list(RETRY_DIR.glob(\"*.wav\"))\n",
    "    print(\"Retry wavs:\", len(retry_wavs))\n",
    "    for src in retry_wavs:\n",
    "        dst = FULL_DIR / src.name\n",
    "        shutil.copy2(src, dst)  # overwrite\n",
    "else:\n",
    "    print(\"No retry dir:\", RETRY_DIR)\n",
    "\n",
    "# helper: patch csv by clip_id\n",
    "def patch_by_clip_id(base_csv: Path, patch_csv: Path, out_csv: Path):\n",
    "    base_df = pd.read_csv(base_csv)\n",
    "    patch_df = pd.read_csv(patch_csv)\n",
    "\n",
    "    base_df[\"clip_id\"] = base_df[\"clip_id\"].astype(str)\n",
    "    patch_df[\"clip_id\"] = patch_df[\"clip_id\"].astype(str)\n",
    "\n",
    "    # remove base rows that will be replaced, then append patch, then sort (optional)\n",
    "    base_df = base_df[~base_df[\"clip_id\"].isin(set(patch_df[\"clip_id\"]))].copy()\n",
    "    merged = pd.concat([base_df, patch_df], ignore_index=True)\n",
    "\n",
    "    merged.to_csv(out_csv, index=False)\n",
    "    return len(patch_df)\n",
    "\n",
    "# 2) patch trim_pad_manifest.csv\n",
    "if MANIFEST.exists() and MANIFEST_RETRY.exists():\n",
    "    n = patch_by_clip_id(MANIFEST, MANIFEST_RETRY, MANIFEST)\n",
    "    print(\"Patched trim_pad_manifest rows:\", n)\n",
    "\n",
    "# 3) patch vad_report.csv\n",
    "if VAD_REPORT.exists() and VAD_REPORT_RETRY.exists():\n",
    "    n = patch_by_clip_id(VAD_REPORT, VAD_REPORT_RETRY, VAD_REPORT)\n",
    "    print(\"Patched vad_report rows:\", n)\n",
    "\n",
    "# 4) vad_drop.csv = vad_drop_retry.csv\n",
    "if VAD_DROP_RETRY.exists():\n",
    "    shutil.copy2(VAD_DROP_RETRY, VAD_DROP)\n",
    "    print(\"Replaced vad_drop.csv with vad_drop_retry.csv\")\n",
    "\n",
    "# 5) delete reextract_failed.csv if empty\n",
    "if REEX_FAILED.exists():\n",
    "    try:\n",
    "        df_fail = pd.read_csv(REEX_FAILED)\n",
    "        if len(df_fail) == 0:\n",
    "            REEX_FAILED.unlink()\n",
    "            print(\"Deleted empty reextract_failed.csv\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# 6) cleanup temp dirs/files (optional but recommended)\n",
    "#   delete retry dir and raw dir, and retry csv files (optional)\n",
    "if RETRY_DIR.exists():\n",
    "    shutil.rmtree(RETRY_DIR)\n",
    "    print(\"Deleted dir:\", RETRY_DIR)\n",
    "\n",
    "if RAW_DIR.exists():\n",
    "    shutil.rmtree(RAW_DIR)\n",
    "    print(\"Deleted dir:\", RAW_DIR)\n",
    "\n",
    "# remove retry csvs (optional)\n",
    "for p in [MANIFEST_RETRY, VAD_REPORT_RETRY, VAD_DROP_RETRY]:\n",
    "    if p.exists():\n",
    "        p.unlink()\n",
    "        print(\"Deleted file:\", p)\n",
    "\n",
    "print(\"\\nDone. Current key files:\")\n",
    "print(\"-\", FULL_DIR)\n",
    "print(\"-\", MANIFEST)\n",
    "print(\"-\", VAD_REPORT)\n",
    "print(\"-\", VAD_DROP)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
