{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1b2f4d6",
   "metadata": {},
   "source": [
    "# **Imports + Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c6fbbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "import warnings\n",
    "\n",
    "TARGET_SR = 16000\n",
    "TARGET_SEC = 15.0\n",
    "MIN_SEC = 1.0\n",
    "MIN_SPEECH_SEC = 2.0\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725f9dab",
   "metadata": {},
   "source": [
    "# **Path split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d7b7b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train audio_dir exists? True -> e:\\tugas-akhir-qiqi\\Dataset\\Train\\train\\audio\n",
      "Val audio_dir exists? True -> e:\\tugas-akhir-qiqi\\Dataset\\Val\\val\\audio\n",
      "Test audio_dir exists? True -> e:\\tugas-akhir-qiqi\\Dataset\\Test\\test\\audio\n"
     ]
    }
   ],
   "source": [
    "ROOT = Path.cwd().parent\n",
    "DATASET = ROOT / \"Dataset\"\n",
    "\n",
    "SPLITS = {\n",
    "    \"Train\": {\n",
    "        \"split_root\": DATASET / \"Train\",\n",
    "        \"audio_dir\":  DATASET / \"Train\" / \"train\" / \"audio\",\n",
    "    },\n",
    "    \"Val\": {\n",
    "        \"split_root\": DATASET / \"Val\",\n",
    "        \"audio_dir\":  DATASET / \"Val\" / \"val\" / \"audio\",\n",
    "    },\n",
    "    \"Test\": {\n",
    "        \"split_root\": DATASET / \"Test\",\n",
    "        \"audio_dir\":  DATASET / \"Test\" / \"test\" / \"audio\",\n",
    "    },\n",
    "}\n",
    "\n",
    "for k,v in SPLITS.items():\n",
    "    print(k, \"audio_dir exists?\", v[\"audio_dir\"].exists(), \"->\", v[\"audio_dir\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eb7991",
   "metadata": {},
   "source": [
    "# **Cek metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c843979d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnG_dev_df shape: (8000, 4)\n",
      "EnG_test_df shape: (2000, 4)\n",
      "Age_dev_df shape: (8000, 3)\n",
      "Age_test_df shape: (2000, 3)\n",
      "\n",
      "\n",
      "EnG_dev_df head:\n",
      "\n",
      "              VideoName    YouTubeID  Ethnicity  Gender\n",
      "0  --Ymqszjv54.001.mp4  --Ymqszjv54          2       1\n",
      "1  --Ymqszjv54.003.mp4  --Ymqszjv54          2       1\n",
      "2  --Ymqszjv54.004.mp4  --Ymqszjv54          2       1\n",
      "3  --Ymqszjv54.005.mp4  --Ymqszjv54          2       1\n",
      "4  -2qsCrkXdWs.001.mp4  -2qsCrkXdWs          2       1\n",
      "EnG_test_df head:\n",
      "\n",
      "              VideoName    YouTubeID  Ethnicity  Gender\n",
      "0  --Ymqszjv54.000.mp4  --Ymqszjv54          2       1\n",
      "1  -10-QQDO_ME.001.mp4  -10-QQDO_ME          2       2\n",
      "2  -10-QQDO_ME.002.mp4  -10-QQDO_ME          2       2\n",
      "3  -10-QQDO_ME.005.mp4  -10-QQDO_ME          2       2\n",
      "4  -4J4xkfN5cI.000.mp4  -4J4xkfN5cI          2       2\n",
      "Age_dev_df head:\n",
      "\n",
      "              VideoName    YouTubeID  AgeGroup\n",
      "0  --Ymqszjv54.001.mp4  --Ymqszjv54         5\n",
      "1  --Ymqszjv54.003.mp4  --Ymqszjv54         5\n",
      "2  --Ymqszjv54.004.mp4  --Ymqszjv54         5\n",
      "3  --Ymqszjv54.005.mp4  --Ymqszjv54         5\n",
      "4  -2qsCrkXdWs.001.mp4  -2qsCrkXdWs         2\n",
      "Age_test_df head:\n",
      "\n",
      "              VideoName    YouTubeID  AgeGroup\n",
      "0  --Ymqszjv54.000.mp4  --Ymqszjv54         6\n",
      "1  -10-QQDO_ME.001.mp4  -10-QQDO_ME         5\n",
      "2  -10-QQDO_ME.002.mp4  -10-QQDO_ME         5\n",
      "3  -10-QQDO_ME.005.mp4  -10-QQDO_ME         5\n",
      "4  -4J4xkfN5cI.000.mp4  -4J4xkfN5cI         2\n"
     ]
    }
   ],
   "source": [
    "#metadata etnichity & gender (csv)\n",
    "EnG_dev_csv = DATASET / \"Eth_gender_annotation\" / \"eth_gender_annotations_dev.csv\"\n",
    "EnG_test_csv = DATASET / \"Eth_gender_annotation\" / \"eth_gender_annotations_test.csv\"\n",
    "\n",
    "#Age Anotation (csv)\n",
    "Age_dev_csv = DATASET / \"Age\" / \"age_anno_dev.csv\"\n",
    "Age_test_csv = DATASET / \"Age\" / \"age_anno_test.csv\"\n",
    "\n",
    "## load metadata csv and print\n",
    "EnG_dev_df = pd.read_csv(EnG_dev_csv, sep=';')\n",
    "EnG_test_df = pd.read_csv(EnG_test_csv, sep=';')\n",
    "Age_dev_df = pd.read_csv(Age_dev_csv)\n",
    "Age_test_df = pd.read_csv(Age_test_csv)\n",
    "print(\"EnG_dev_df shape:\", EnG_dev_df.shape)\n",
    "print(\"EnG_test_df shape:\", EnG_test_df.shape)\n",
    "print(\"Age_dev_df shape:\", Age_dev_df.shape)\n",
    "print(\"Age_test_df shape:\", Age_test_df.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(\"EnG_dev_df head:\\n\\n\", EnG_dev_df.head())\n",
    "    print(\"EnG_test_df head:\\n\\n\", EnG_test_df.head())\n",
    "    print(\"Age_dev_df head:\\n\\n\", Age_dev_df.head())\n",
    "    print(\"Age_test_df head:\\n\\n\", Age_test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6899aa3",
   "metadata": {},
   "source": [
    "Karena ada dev dan test yang ada di EnG dan juga di Age csv, maka keputusan yaitu merge jadi 2 metadata, yaitu dev dan test dan digabungin sekalian dengan Big 5 yang ada di anotasi tiap split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb77c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Train =====\n",
      "annotation dir: e:\\tugas-akhir-qiqi\\Dataset\\Train\\annotation\n",
      "PKL found: ['annotation_training.pkl']\n",
      "Using PKL: annotation_training.pkl | size: 793769\n",
      "Loaded type: <class 'dict'>\n",
      "Dict keys sample: ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'interview', 'openness']\n",
      "First value type: <class 'dict'>\n",
      "pd.DataFrame(obj) shape: (6000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>interview</th>\n",
       "      <th>openness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>J4GQm9j0JZ0.003.mp4</th>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>0.601942</td>\n",
       "      <td>0.504673</td>\n",
       "      <td>0.488889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zEyRyTnIw5I.005.mp4</th>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nskJh7v6v1U.004.mp4</th>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>0.373832</td>\n",
       "      <td>0.511111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6wHQsN5g2RM.000.mp4</th>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.505495</td>\n",
       "      <td>0.398058</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.377778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dQOeQYWIgm8.000.mp4</th>\n",
       "      <td>0.607477</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.622222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     extraversion  neuroticism  agreeableness  \\\n",
       "J4GQm9j0JZ0.003.mp4      0.523364     0.552083       0.626374   \n",
       "zEyRyTnIw5I.005.mp4      0.345794     0.375000       0.472527   \n",
       "nskJh7v6v1U.004.mp4      0.252336     0.291667       0.406593   \n",
       "6wHQsN5g2RM.000.mp4      0.457944     0.489583       0.505495   \n",
       "dQOeQYWIgm8.000.mp4      0.607477     0.489583       0.406593   \n",
       "\n",
       "                     conscientiousness  interview  openness  \n",
       "J4GQm9j0JZ0.003.mp4           0.601942   0.504673  0.488889  \n",
       "zEyRyTnIw5I.005.mp4           0.582524   0.457944  0.366667  \n",
       "nskJh7v6v1U.004.mp4           0.485437   0.373832  0.511111  \n",
       "6wHQsN5g2RM.000.mp4           0.398058   0.457944  0.377778  \n",
       "dQOeQYWIgm8.000.mp4           0.621359   0.570093  0.622222  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index sample: ['J4GQm9j0JZ0.003.mp4', 'zEyRyTnIw5I.005.mp4', 'nskJh7v6v1U.004.mp4', '6wHQsN5g2RM.000.mp4', 'dQOeQYWIgm8.000.mp4', 'eHcRre1YsNA.000.mp4', 'vZpneJlniAE.005.mp4', 'oANKg9_grdA.004.mp4', 'VuadgOz6T7s.000.mp4', '7nhJXn9PI0I.001.mp4']\n",
      "Columns sample: ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'interview', 'openness']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def load_pkl(path: Path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        try:\n",
    "            return pickle.load(f)\n",
    "        except UnicodeDecodeError:\n",
    "            f.seek(0)\n",
    "            return pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "def inspect_annotation(split_name: str):\n",
    "    ann_dir = SPLITS[split_name][\"split_root\"] / \"annotation\"\n",
    "    print(f\"\\n===== {split_name} =====\")\n",
    "    print(\"annotation dir:\", ann_dir)\n",
    "\n",
    "    if not ann_dir.exists():\n",
    "        print(\"-> annotation folder tidak ada\")\n",
    "        return\n",
    "\n",
    "    pkls = sorted(list(ann_dir.glob(\"*.pkl\")) + list(ann_dir.glob(\"*.pickle\")))\n",
    "    print(\"PKL found:\", [p.name for p in pkls])\n",
    "\n",
    "    if not pkls:\n",
    "        print(\"-> tidak ada pkl\")\n",
    "        return\n",
    "\n",
    "    # pilih pkl terbesar (biasanya utama)\n",
    "    pkl_path = max(pkls, key=lambda p: p.stat().st_size)\n",
    "    print(\"Using PKL:\", pkl_path.name, \"| size:\", pkl_path.stat().st_size)\n",
    "\n",
    "    obj = load_pkl(pkl_path)\n",
    "    print(\"Loaded type:\", type(obj))\n",
    "\n",
    "    # kalau sudah DataFrame\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        df = obj\n",
    "        print(\"Already DataFrame. shape:\", df.shape)\n",
    "        display(df.head())\n",
    "        return\n",
    "\n",
    "    # kalau dict\n",
    "    if isinstance(obj, dict):\n",
    "        keys = list(obj.keys())\n",
    "        print(\"Dict keys sample:\", keys[:10])\n",
    "        first_key = keys[0] if keys else None\n",
    "        first_val = obj[first_key] if first_key is not None else None\n",
    "        print(\"First value type:\", type(first_val))\n",
    "\n",
    "        # Coba bikin DataFrame (akan benar kalau dict-of-dict atau dict-of-list)\n",
    "        try:\n",
    "            df = pd.DataFrame(obj)\n",
    "            print(\"pd.DataFrame(obj) shape:\", df.shape)\n",
    "            display(df.head())\n",
    "            print(\"Index sample:\", list(df.index)[:10])\n",
    "            print(\"Columns sample:\", list(df.columns)[:10])\n",
    "\n",
    "            # indikasi butuh transpose:\n",
    "            # - kalau index itu trait (extraversion, openness, ...) dan columns itu video, maka harus transpose\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(\"pd.DataFrame(obj) failed:\", e)\n",
    "            return\n",
    "\n",
    "    # kalau list\n",
    "    if isinstance(obj, list):\n",
    "        print(\"List len:\", len(obj))\n",
    "        print(\"First elem type:\", type(obj[0]) if obj else None)\n",
    "        try:\n",
    "            df = pd.DataFrame(obj)\n",
    "            print(\"pd.DataFrame(list) shape:\", df.shape)\n",
    "            display(df.head())\n",
    "        except Exception as e:\n",
    "            print(\"pd.DataFrame(list) failed:\", e)\n",
    "        return\n",
    "\n",
    "    # tipe lain\n",
    "    print(\"Unhandled type; coba print repr pendek:\")\n",
    "    print(repr(obj)[:500])\n",
    "\n",
    "# Jalankan satu-satu\n",
    "inspect_annotation(\"Train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add07cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Val =====\n",
      "annotation dir: e:\\tugas-akhir-qiqi\\Dataset\\Val\\annotation\n",
      "PKL found: ['annotation_validation.pkl']\n",
      "Using PKL: annotation_validation.pkl | size: 261721\n",
      "Loaded type: <class 'dict'>\n",
      "Dict keys sample: ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'interview', 'openness']\n",
      "First value type: <class 'dict'>\n",
      "pd.DataFrame(obj) shape: (2000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>interview</th>\n",
       "      <th>openness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>modNfUPt3F4.002.mp4</th>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h6LOjpCRXtY.005.mp4</th>\n",
       "      <td>0.439252</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.417582</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>0.439252</td>\n",
       "      <td>0.411111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WER4ww680QQ.004.mp4</th>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.398058</td>\n",
       "      <td>0.373832</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4XnKouozXU.002.mp4</th>\n",
       "      <td>0.364486</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.553398</td>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.322222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OEKg-Tvwcbk.002.mp4</th>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.516484</td>\n",
       "      <td>0.417476</td>\n",
       "      <td>0.383178</td>\n",
       "      <td>0.477778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     extraversion  neuroticism  agreeableness  \\\n",
       "modNfUPt3F4.002.mp4      0.644860     0.593750       0.615385   \n",
       "h6LOjpCRXtY.005.mp4      0.439252     0.520833       0.417582   \n",
       "WER4ww680QQ.004.mp4      0.457944     0.312500       0.428571   \n",
       "c4XnKouozXU.002.mp4      0.364486     0.572917       0.527473   \n",
       "OEKg-Tvwcbk.002.mp4      0.345794     0.468750       0.516484   \n",
       "\n",
       "                     conscientiousness  interview  openness  \n",
       "modNfUPt3F4.002.mp4           0.640777   0.616822  0.555556  \n",
       "h6LOjpCRXtY.005.mp4           0.572816   0.439252  0.411111  \n",
       "WER4ww680QQ.004.mp4           0.398058   0.373832  0.555556  \n",
       "c4XnKouozXU.002.mp4           0.553398   0.523364  0.322222  \n",
       "OEKg-Tvwcbk.002.mp4           0.417476   0.383178  0.477778  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index sample: ['modNfUPt3F4.002.mp4', 'h6LOjpCRXtY.005.mp4', 'WER4ww680QQ.004.mp4', 'c4XnKouozXU.002.mp4', 'OEKg-Tvwcbk.002.mp4', 'PtA7yAu9-VE.003.mp4', 'TmpP2fXeVtk.004.mp4', '1uC-2TZqplE.002.mp4', '_01AyUz9J9I.003.mp4', '_RfHkyf68Zs.000.mp4']\n",
      "Columns sample: ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'interview', 'openness']\n"
     ]
    }
   ],
   "source": [
    "inspect_annotation(\"Val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26325c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Test =====\n",
      "annotation dir: e:\\tugas-akhir-qiqi\\Dataset\\Test\\annotation\n",
      "PKL found: ['annotation_test.pkl']\n",
      "Using PKL: annotation_test.pkl | size: 261721\n",
      "Loaded type: <class 'dict'>\n",
      "Dict keys sample: ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'interview', 'openness']\n",
      "First value type: <class 'dict'>\n",
      "pd.DataFrame(obj) shape: (2000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>interview</th>\n",
       "      <th>openness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>htH89DBizno.004.mp4</th>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.822222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_wf-KszNlk.001.mp4</th>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.514563</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.655556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuYYY3XaJ7Q.001.mp4</th>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.560440</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>0.514019</td>\n",
       "      <td>0.522222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0MB91ku0eEw.005.mp4</th>\n",
       "      <td>0.411215</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.660194</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WpEZOSrENL0.003.mp4</th>\n",
       "      <td>0.317757</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.411111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     extraversion  neuroticism  agreeableness  \\\n",
       "htH89DBizno.004.mp4      0.485981     0.645833       0.681319   \n",
       "p_wf-KszNlk.001.mp4      0.616822     0.593750       0.692308   \n",
       "MuYYY3XaJ7Q.001.mp4      0.467290     0.625000       0.560440   \n",
       "0MB91ku0eEw.005.mp4      0.411215     0.458333       0.714286   \n",
       "WpEZOSrENL0.003.mp4      0.317757     0.437500       0.384615   \n",
       "\n",
       "                     conscientiousness  interview  openness  \n",
       "htH89DBizno.004.mp4           0.669903   0.626168  0.822222  \n",
       "p_wf-KszNlk.001.mp4           0.514563   0.570093  0.655556  \n",
       "MuYYY3XaJ7Q.001.mp4           0.524272   0.514019  0.522222  \n",
       "0MB91ku0eEw.005.mp4           0.660194   0.570093  0.400000  \n",
       "WpEZOSrENL0.003.mp4           0.524272   0.448598  0.411111  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index sample: ['htH89DBizno.004.mp4', 'p_wf-KszNlk.001.mp4', 'MuYYY3XaJ7Q.001.mp4', '0MB91ku0eEw.005.mp4', 'WpEZOSrENL0.003.mp4', 'C2Y9Puk3Obk.004.mp4', 'ask-ZFRztf8.003.mp4', 'TSGpD2NBeCQ.005.mp4', '54JawR1x0II.004.mp4', '9n8dNi-ERQ0.001.mp4']\n",
      "Columns sample: ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'interview', 'openness']\n"
     ]
    }
   ],
   "source": [
    "inspect_annotation(\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3ce5ba",
   "metadata": {},
   "source": [
    "# **Cek Leakage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cebb3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Leakage Check (Group-level) ===\n",
      "Group ID definition: group_id = clip_id.split('.')[0]  (≈ YouTubeID)\n",
      "\n",
      "1) Official split sizes (by extracted audio):\n",
      "   - Train clips: 6,000 | unique groups: 2,624\n",
      "   - Val   clips: 2,000 | unique groups: 1,484\n",
      "   - Test  clips: 2,000 | unique groups: 1,455\n",
      "\n",
      "2) Group overlaps (potential identity leakage):\n",
      "   - Train ∩ Val : 1,222 groups (82.35% of Val groups)\n",
      "   - Train ∩ Test: 1,201 groups (82.54% of Test groups)\n",
      "   - Val   ∩ Test: 689 groups (47.35% of Test groups)\n",
      "\n",
      "3) Test leakage from Train/Val combined:\n",
      "   - (Train ∪ Val) ∩ Test: 1,281 groups (88.04% of Test groups)\n",
      "\n",
      "4) Verdict:\n",
      "   - Group overlap detected between (Train ∪ Val) and Test (identity leakage risk).\n",
      "\n",
      "5) Sample overlapping group IDs:\n",
      "   - Train∩Test sample: --Ymqszjv54, -6otZ7M-Mro, -8asrRvfJWA, -DOqN0d8KHw, -Gl98Jn45Fs, -N6QKrbnaDs, -NwfYYf5xLo, -R2SZu3SYgM, -VTqcHNgH7M, -Wqk9eex6bQ\n",
      "   - Val∩Test   sample: -6otZ7M-Mro, -8asrRvfJWA, -DOqN0d8KHw, -N6QKrbnaDs, -PWjgx2czwY, -R2SZu3SYgM, -RqxrwIxMvE, -VTqcHNgH7M, -Wqk9eex6bQ, -agCXYgb7pI\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def group_id_from_clip_id(clip_id: str) -> str:\n",
    "    # contoh: \"--Ymqszjv54.001\" -> \"--Ymqszjv54\"\n",
    "    return str(clip_id).split(\".\")[0]\n",
    "\n",
    "def get_clip_ids_from_audio(audio_dir: Path):\n",
    "    return {p.stem for p in audio_dir.glob(\"*.wav\")}\n",
    "\n",
    "def pct(a, b):\n",
    "    return (a / b * 100) if b else 0.0\n",
    "\n",
    "def report_leakage():\n",
    "    train_ids = get_clip_ids_from_audio(SPLITS[\"Train\"][\"audio_dir\"])\n",
    "    val_ids   = get_clip_ids_from_audio(SPLITS[\"Val\"][\"audio_dir\"])\n",
    "    test_ids  = get_clip_ids_from_audio(SPLITS[\"Test\"][\"audio_dir\"])\n",
    "\n",
    "    G_train = {group_id_from_clip_id(x) for x in train_ids}\n",
    "    G_val   = {group_id_from_clip_id(x) for x in val_ids}\n",
    "    G_test  = {group_id_from_clip_id(x) for x in test_ids}\n",
    "\n",
    "    # overlaps\n",
    "    ov_tv = G_train & G_val\n",
    "    ov_tt = G_train & G_test\n",
    "    ov_vt = G_val & G_test\n",
    "    ov_any_test = (G_train | G_val) & G_test\n",
    "\n",
    "    lines = []\n",
    "    lines.append(\"=== Leakage Check (Group-level) ===\")\n",
    "    lines.append(\"Group ID definition: group_id = clip_id.split('.')[0]  (≈ YouTubeID)\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"1) Official split sizes (by extracted audio):\")\n",
    "    lines.append(f\"   - Train clips: {len(train_ids):,} | unique groups: {len(G_train):,}\")\n",
    "    lines.append(f\"   - Val   clips: {len(val_ids):,} | unique groups: {len(G_val):,}\")\n",
    "    lines.append(f\"   - Test  clips: {len(test_ids):,} | unique groups: {len(G_test):,}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"2) Group overlaps (potential identity leakage):\")\n",
    "    lines.append(f\"   - Train ∩ Val : {len(ov_tv):,} groups ({pct(len(ov_tv), len(G_val)):.2f}% of Val groups)\")\n",
    "    lines.append(f\"   - Train ∩ Test: {len(ov_tt):,} groups ({pct(len(ov_tt), len(G_test)):.2f}% of Test groups)\")\n",
    "    lines.append(f\"   - Val   ∩ Test: {len(ov_vt):,} groups ({pct(len(ov_vt), len(G_test)):.2f}% of Test groups)\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"3) Test leakage from Train/Val combined:\")\n",
    "    lines.append(f\"   - (Train ∪ Val) ∩ Test: {len(ov_any_test):,} groups ({pct(len(ov_any_test), len(G_test)):.2f}% of Test groups)\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # judgement\n",
    "    if len(ov_any_test) == 0:\n",
    "        verdict = \"No group overlap detected between (Train ∪ Val) and Test (clean at group-level).\"\n",
    "    else:\n",
    "        verdict = \"Group overlap detected between (Train ∪ Val) and Test (identity leakage risk).\"\n",
    "    lines.append(\"4) Verdict:\")\n",
    "    lines.append(f\"   - {verdict}\")\n",
    "\n",
    "    # sample overlaps\n",
    "    def sample_list(s, n=10):\n",
    "        return \", \".join(list(sorted(s))[:n]) if s else \"-\"\n",
    "\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"5) Sample overlapping group IDs:\")\n",
    "    lines.append(f\"   - Train∩Test sample: {sample_list(ov_tt)}\")\n",
    "    lines.append(f\"   - Val∩Test   sample: {sample_list(ov_vt)}\")\n",
    "\n",
    "    print(\"\\n\".join(lines))\n",
    "\n",
    "report_leakage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec667e2f",
   "metadata": {},
   "source": [
    "# **Build Metadata**\n",
    "\n",
    "Akan ada 4 metadata output (Dengan gabungan EnG, anotasi official, dan Age)\n",
    "- meta_train_official.csv\n",
    "- meta_val_official.csv\n",
    "- meta_test_official.csv\n",
    "- meta_master.csv (akan digunakan di split strict, yang mana ini gabungan dari train val dan test, dengan tambahan kolom source official (train, test, val)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca66e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = ROOT / \"output\" / \"preprocessing\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def norm_clip(x: str) -> str:\n",
    "    return Path(str(x)).stem  # \"--Ymqszjv54.001.mp4\" -> \"--Ymqszjv54.001\"\n",
    "\n",
    "def group_id_from_clip_id(clip_id: str) -> str:\n",
    "    return str(clip_id).split(\".\")[0]  # \"--Ymqszjv54.001\" -> \"--Ymqszjv54\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ebb84e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnG_dev: (8000, 4) | EnG_test: (2000, 4)\n",
      "Age_dev: (8000, 3) | Age_test: (2000, 3)\n"
     ]
    }
   ],
   "source": [
    "# EnG Anotation (csv)\n",
    "EnG_dev_csv = DATASET / \"Eth_gender_annotation\" / \"eth_gender_annotations_dev.csv\"\n",
    "EnG_test_csv = DATASET / \"Eth_gender_annotation\" / \"eth_gender_annotations_test.csv\"\n",
    "\n",
    "# Age Anotation (csv)\n",
    "Age_dev_csv = DATASET / \"Age\" / \"age_anno_dev.csv\"\n",
    "Age_test_csv = DATASET / \"Age\" / \"age_anno_test.csv\"\n",
    "\n",
    "EnG_dev_df = pd.read_csv(EnG_dev_csv, sep=';')\n",
    "EnG_test_df = pd.read_csv(EnG_test_csv, sep=';')\n",
    "Age_dev_df = pd.read_csv(Age_dev_csv)\n",
    "Age_test_df = pd.read_csv(Age_test_csv)\n",
    "\n",
    "print(\"EnG_dev:\", EnG_dev_df.shape, \"| EnG_test:\", EnG_test_df.shape)\n",
    "print(\"Age_dev:\", Age_dev_df.shape, \"| Age_test:\", Age_test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a35ffde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_dev: (8000, 7)\n",
      "meta_test: (2000, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VideoName</th>\n",
       "      <th>YouTubeID</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Gender</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--Ymqszjv54.001.mp4</td>\n",
       "      <td>--Ymqszjv54</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>--Ymqszjv54.001</td>\n",
       "      <td>5</td>\n",
       "      <td>--Ymqszjv54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--Ymqszjv54.003.mp4</td>\n",
       "      <td>--Ymqszjv54</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>--Ymqszjv54.003</td>\n",
       "      <td>5</td>\n",
       "      <td>--Ymqszjv54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--Ymqszjv54.004.mp4</td>\n",
       "      <td>--Ymqszjv54</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>--Ymqszjv54.004</td>\n",
       "      <td>5</td>\n",
       "      <td>--Ymqszjv54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--Ymqszjv54.005.mp4</td>\n",
       "      <td>--Ymqszjv54</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>--Ymqszjv54.005</td>\n",
       "      <td>5</td>\n",
       "      <td>--Ymqszjv54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2qsCrkXdWs.001.mp4</td>\n",
       "      <td>-2qsCrkXdWs</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2qsCrkXdWs.001</td>\n",
       "      <td>2</td>\n",
       "      <td>-2qsCrkXdWs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             VideoName    YouTubeID  Ethnicity  Gender          clip_id  \\\n",
       "0  --Ymqszjv54.001.mp4  --Ymqszjv54          2       1  --Ymqszjv54.001   \n",
       "1  --Ymqszjv54.003.mp4  --Ymqszjv54          2       1  --Ymqszjv54.003   \n",
       "2  --Ymqszjv54.004.mp4  --Ymqszjv54          2       1  --Ymqszjv54.004   \n",
       "3  --Ymqszjv54.005.mp4  --Ymqszjv54          2       1  --Ymqszjv54.005   \n",
       "4  -2qsCrkXdWs.001.mp4  -2qsCrkXdWs          2       1  -2qsCrkXdWs.001   \n",
       "\n",
       "   AgeGroup     group_id  \n",
       "0         5  --Ymqszjv54  \n",
       "1         5  --Ymqszjv54  \n",
       "2         5  --Ymqszjv54  \n",
       "3         5  --Ymqszjv54  \n",
       "4         2  -2qsCrkXdWs  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for df in [EnG_dev_df, EnG_test_df, Age_dev_df, Age_test_df]:\n",
    "    df[\"clip_id\"] = df[\"VideoName\"].map(norm_clip)\n",
    "\n",
    "meta_dev = EnG_dev_df.merge(Age_dev_df[[\"clip_id\", \"AgeGroup\"]], on=\"clip_id\", how=\"left\")\n",
    "meta_test = EnG_test_df.merge(Age_test_df[[\"clip_id\", \"AgeGroup\"]], on=\"clip_id\", how=\"left\")\n",
    "\n",
    "# tambah group_id\n",
    "meta_dev[\"group_id\"] = meta_dev[\"clip_id\"].map(group_id_from_clip_id)\n",
    "meta_test[\"group_id\"] = meta_test[\"clip_id\"].map(group_id_from_clip_id)\n",
    "\n",
    "print(\"meta_dev:\", meta_dev.shape)\n",
    "print(\"meta_test:\", meta_test.shape)\n",
    "display(meta_dev.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8228cb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigFive Train: (6000, 8) | src: e:\\tugas-akhir-qiqi\\Dataset\\Train\\annotation\\annotation_training.pkl\n",
      "BigFive Val  : (2000, 8) | src: e:\\tugas-akhir-qiqi\\Dataset\\Val\\annotation\\annotation_validation.pkl\n",
      "BigFive Test : (2000, 8) | src: e:\\tugas-akhir-qiqi\\Dataset\\Test\\annotation\\annotation_test.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_id</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>openness</th>\n",
       "      <th>interview</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J4GQm9j0JZ0.003</td>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>0.601942</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.504673</td>\n",
       "      <td>J4GQm9j0JZ0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zEyRyTnIw5I.005</td>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>zEyRyTnIw5I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nskJh7v6v1U.004</td>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.373832</td>\n",
       "      <td>nskJh7v6v1U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6wHQsN5g2RM.000</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.505495</td>\n",
       "      <td>0.398058</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>6wHQsN5g2RM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dQOeQYWIgm8.000</td>\n",
       "      <td>0.607477</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>dQOeQYWIgm8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           clip_id  extraversion  neuroticism  agreeableness  \\\n",
       "0  J4GQm9j0JZ0.003      0.523364     0.552083       0.626374   \n",
       "1  zEyRyTnIw5I.005      0.345794     0.375000       0.472527   \n",
       "2  nskJh7v6v1U.004      0.252336     0.291667       0.406593   \n",
       "3  6wHQsN5g2RM.000      0.457944     0.489583       0.505495   \n",
       "4  dQOeQYWIgm8.000      0.607477     0.489583       0.406593   \n",
       "\n",
       "   conscientiousness  openness  interview     group_id  \n",
       "0           0.601942  0.488889   0.504673  J4GQm9j0JZ0  \n",
       "1           0.582524  0.366667   0.457944  zEyRyTnIw5I  \n",
       "2           0.485437  0.511111   0.373832  nskJh7v6v1U  \n",
       "3           0.398058  0.377778   0.457944  6wHQsN5g2RM  \n",
       "4           0.621359  0.622222   0.570093  dQOeQYWIgm8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_pkl(path: Path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        try:\n",
    "            return pickle.load(f)\n",
    "        except UnicodeDecodeError:\n",
    "            f.seek(0)\n",
    "            return pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "def load_bigfive_from_split(split_name: str) -> pd.DataFrame:\n",
    "    ann_dir = SPLITS[split_name][\"split_root\"] / \"annotation\"\n",
    "    pkls = sorted(list(ann_dir.glob(\"*.pkl\")) + list(ann_dir.glob(\"*.pickle\")))\n",
    "    if not pkls:\n",
    "        raise FileNotFoundError(f\"Tidak ada PKL di: {ann_dir}\")\n",
    "\n",
    "    pkl_path = max(pkls, key=lambda p: p.stat().st_size)\n",
    "    obj = load_pkl(pkl_path)\n",
    "\n",
    "    if not isinstance(obj, dict):\n",
    "        raise ValueError(f\"Format PKL bukan dict: {type(obj)} (file: {pkl_path.name})\")\n",
    "\n",
    "    # dict-of-dict (trait -> {clip: value}) -> DataFrame: rows=clip, cols=trait\n",
    "    df = pd.DataFrame(obj)\n",
    "\n",
    "    # index biasanya nama file clip (kadang ada .mp4)\n",
    "    df = df.reset_index().rename(columns={\"index\": \"clip_id\"})\n",
    "    df[\"clip_id\"] = df[\"clip_id\"].astype(str).map(norm_clip)\n",
    "\n",
    "    # keep 5 trait utama (+ interview kalau ada)\n",
    "    keep = [\"clip_id\", \"extraversion\", \"neuroticism\", \"agreeableness\", \"conscientiousness\", \"openness\"]\n",
    "    if \"interview\" in df.columns:\n",
    "        keep.append(\"interview\")\n",
    "    for c in keep:\n",
    "        if c not in df.columns:\n",
    "            df[c] = np.nan\n",
    "\n",
    "    # numeric\n",
    "    for c in [\"extraversion\",\"neuroticism\",\"agreeableness\",\"conscientiousness\",\"openness\",\"interview\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    df[\"group_id\"] = df[\"clip_id\"].map(group_id_from_clip_id)\n",
    "    df.attrs[\"source\"] = str(pkl_path)\n",
    "    return df[keep + [\"group_id\"]]\n",
    "\n",
    "big_train = load_bigfive_from_split(\"Train\")\n",
    "big_val   = load_bigfive_from_split(\"Val\")\n",
    "big_test  = load_bigfive_from_split(\"Test\")\n",
    "\n",
    "print(\"BigFive Train:\", big_train.shape, \"| src:\", big_train.attrs.get(\"source\"))\n",
    "print(\"BigFive Val  :\", big_val.shape,   \"| src:\", big_val.attrs.get(\"source\"))\n",
    "print(\"BigFive Test :\", big_test.shape,  \"| src:\", big_test.attrs.get(\"source\"))\n",
    "display(big_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44400eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio counts: 6000 2000 2000\n"
     ]
    }
   ],
   "source": [
    "def audio_clip_ids(audio_dir: Path) -> set[str]:\n",
    "    return {p.stem for p in audio_dir.glob(\"*.wav\")}\n",
    "\n",
    "train_ids = audio_clip_ids(SPLITS[\"Train\"][\"audio_dir\"])\n",
    "val_ids   = audio_clip_ids(SPLITS[\"Val\"][\"audio_dir\"])\n",
    "test_ids  = audio_clip_ids(SPLITS[\"Test\"][\"audio_dir\"])\n",
    "\n",
    "print(\"audio counts:\", len(train_ids), len(val_ids), len(test_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbb227c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_train_off: (6000, 13)\n",
      "meta_val_off  : (2000, 13)\n",
      "meta_test_off : (2000, 13)\n",
      "meta_master   : (10000, 13)\n",
      "duplicated clip_id in meta_master: 0\n",
      "\n",
      "Saved to: E:\\tugas-akhir-qiqi\\output\\preprocessing\n"
     ]
    }
   ],
   "source": [
    "def build_official_meta(split_name: str) -> pd.DataFrame:\n",
    "    if split_name == \"Train\":\n",
    "        ids = train_ids\n",
    "        demo = meta_dev\n",
    "        big = big_train\n",
    "        split_off = \"train\"\n",
    "    elif split_name == \"Val\":\n",
    "        ids = val_ids\n",
    "        demo = meta_dev\n",
    "        big = big_val\n",
    "        split_off = \"val\"\n",
    "    else:\n",
    "        ids = test_ids\n",
    "        demo = meta_test\n",
    "        big = big_test\n",
    "        split_off = \"test\"\n",
    "\n",
    "    demo_s = demo[demo[\"clip_id\"].isin(ids)].copy()\n",
    "    big_s  = big[big[\"clip_id\"].isin(ids)].copy()\n",
    "\n",
    "    # merge demo + bigfive\n",
    "    out = demo_s.merge(big_s.drop(columns=[\"group_id\"]), on=\"clip_id\", how=\"left\", suffixes=(\"\", \"_bf\"))\n",
    "    out[\"split_official\"] = split_off\n",
    "    out[\"group_id\"] = out[\"clip_id\"].map(group_id_from_clip_id)\n",
    "\n",
    "    # rapihin kolom (optional)\n",
    "    prefer_cols = [\n",
    "        \"group_id\",\"clip_id\",\"split_official\",\n",
    "        \"VideoName\",\"Ethnicity\",\"Gender\",\"AgeGroup\",\n",
    "        \"extraversion\",\"neuroticism\",\"agreeableness\",\"conscientiousness\",\"openness\"\n",
    "    ]\n",
    "    if \"interview\" in out.columns:\n",
    "        prefer_cols.append(\"interview\")\n",
    "\n",
    "    cols = [c for c in prefer_cols if c in out.columns] + [c for c in out.columns if c not in prefer_cols]\n",
    "    out = out[cols]\n",
    "    out = out.drop(columns=[\"YouTubeID\"], errors=\"ignore\")\n",
    "    return out\n",
    "\n",
    "meta_train_off = build_official_meta(\"Train\")\n",
    "meta_val_off   = build_official_meta(\"Val\")\n",
    "meta_test_off  = build_official_meta(\"Test\")\n",
    "\n",
    "# meta_master = gabungan train+val+test (10k) untuk strict split\n",
    "meta_master = pd.concat([meta_train_off, meta_val_off, meta_test_off], ignore_index=True)\n",
    "\n",
    "# sanity checks\n",
    "print(\"meta_train_off:\", meta_train_off.shape)\n",
    "print(\"meta_val_off  :\", meta_val_off.shape)\n",
    "print(\"meta_test_off :\", meta_test_off.shape)\n",
    "print(\"meta_master   :\", meta_master.shape)\n",
    "\n",
    "# pastikan unique clip_id\n",
    "dup = meta_master[\"clip_id\"].duplicated().sum()\n",
    "print(\"duplicated clip_id in meta_master:\", dup)\n",
    "\n",
    "# save\n",
    "(meta_train_off).to_csv(OUT_DIR / \"meta_train_official.csv\", index=False)\n",
    "(meta_val_off).to_csv(OUT_DIR / \"meta_val_official.csv\", index=False)\n",
    "(meta_test_off).to_csv(OUT_DIR / \"meta_test_official.csv\", index=False)\n",
    "(meta_master).to_csv(OUT_DIR / \"meta_master.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved to:\", OUT_DIR.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
